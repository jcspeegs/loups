{"config":{"lang":["en"],"separator":"[\\s\\u200b\\-_,:!=\\[\\]()\"`/]+|\\.(?!\\d)|&[lg]t;|(?!\\b)(?=[A-Z][a-z])","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Home","text":""},{"location":"#loups","title":"Loups","text":"Automated Video Chapter Generation Powered by Template Matching &amp; OCR <p> Get Started Documentation GitHub</p>"},{"location":"#what-is-loups","title":"What is Loups?","text":"<p>Loups automatically scans videos with on-screen text overlays to extract information and generate timestamped YouTube chapters. Originally designed for Lights Out HB fastpitch softball games, but works with any video content that has consistent identifying frames or text overlays.</p>"},{"location":"#template-matching","title":"Template Matching","text":"<p>Detects specific frames using image templates - your \"trigger\" for chapter detection</p>"},{"location":"#ocr-extraction","title":"OCR Extraction","text":"<p>Reads text from matched frames with confidence-based filtering for accuracy</p>"},{"location":"#smart-timestamps","title":"Smart Timestamps","text":"<p>Combines extracted text with video timestamps to create chapter entries</p>"},{"location":"#youtube-ready","title":"YouTube Ready","text":"<p>Exports chapters in YouTube-ready format - copy and paste into descriptions</p>"},{"location":"#thumbnail-extraction","title":"Thumbnail Extraction","text":"<p>SSIM-based automatic thumbnail extraction with first-match strategy</p>"},{"location":"#fast-processing","title":"Fast Processing","text":"<p>Efficient video frame analysis with progress tracking and quiet mode</p>"},{"location":"#quick-start","title":"Quick Start","text":"<p>Get Started in Seconds</p> <pre><code># Install from PyPI\npip install loups\n\n# Scan a Lights Out HB game (uses bundled template)\nloups game_video.mp4\n\n# Or use your own template for any video\nloups -t my_template.png -o chapters.txt video.mp4\n</code></pre> <p>Expected output:</p> <pre><code>Scanning video: game_video.mp4\n\n\ud83e\udd4e Scanning batters...  [Progress updates]\n\n\ud83c\udfc6 Scan complete! Found 12 batters in 5.2s\n\nYouTube Chapters:\n0:00:00 Game Start\n0:01:15 Sarah Johnson #7\n0:03:42 Emma Martinez #12\n0:05:23 Lily Garcia #9\n0:08:14 Olivia Brown #5\n...\n</code></pre>"},{"location":"#use-cases","title":"Use Cases","text":"<p> Sports Games Track player at-bats, shifts, appearances</p> <p> Educational Content Chapter markers for topics or speakers</p> <p> Podcasts/Interviews Detect guest overlays or topic cards</p> <p> Gaming Mark level changes or character selections</p> <p> TV Shows Detect episode titles or scene markers</p> <p> Any Video With consistent text overlays or frames</p>"},{"location":"#why-loups","title":"Why Loups?","text":"<p>Modern &amp; Powerful</p> <ul> <li> Universal - Works with any video content</li> <li> Accurate - Confidence-based OCR filtering</li> <li> Fast - Efficient frame processing</li> <li> Automated - Perfect for batch processing</li> <li> Cross-Platform - Linux, macOS, Windows</li> </ul> <p>Platform Support</p> <p>Python 3.13+ required</p> <ul> <li> Linux - Fully tested via CI/CD</li> <li> macOS - Fully tested via CI/CD</li> <li> Windows - Fully tested via CI/CD</li> </ul>"},{"location":"#how-it-works","title":"How It Works","text":"<pre><code>graph LR\n    A[\ud83c\udfa5 Video Input] --&gt; B[\ud83c\udfaf Template Matching]\n    B --&gt; C[\ud83d\udcdd OCR Extraction]\n    C --&gt; D[\ud83d\udccb Chapter Creation]\n    D --&gt; E[\ud83d\udce4 YouTube Format]\n\n    style A fill:#1a1a1a,stroke:#00ffff,color:#00ffff,stroke-width:3px\n    style B fill:#1a1a1a,stroke:#00ffff,color:#00ffff,stroke-width:3px\n    style C fill:#1a1a1a,stroke:#00ffff,color:#00ffff,stroke-width:3px\n    style D fill:#1a1a1a,stroke:#00ffff,color:#00ffff,stroke-width:3px\n    style E fill:#1a1a1a,stroke:#00ffff,color:#00ffff,stroke-width:3px</code></pre> <ol> <li>Template Matching - Scans frames looking for your template image</li> <li>OCR Text Extraction - Reads visible text from matched frames</li> <li>Chapter Creation - Combines text with timestamps</li> <li>Export - Generates YouTube-ready chapter format</li> </ol> <p>Learn more about the process </p>"},{"location":"#open-source","title":"Open Source","text":"<p>Loups is MIT licensed and welcomes contributions!</p> <ul> <li> Report bugs</li> <li> Suggest features</li> <li> Contribute code</li> <li> Share your use cases!</li> </ul> <p>Made with :heart: for content creators :movie_camera:</p> <p>Originally created for Lights Out HB fastpitch softball coverage</p>"},{"location":"api/","title":"API Reference","text":"<p>Complete API documentation for using Loups programmatically in your Python projects.</p>"},{"location":"api/#module-overview","title":"Module Overview","text":"<p>Loups provides a clean Python API for video chapter generation and thumbnail extraction.</p>"},{"location":"api/#loups-class","title":"Loups Class","text":"<p>Main class for video processing and chapter generation</p>"},{"location":"api/#cli-module","title":"CLI Module","text":"<p>Command-line interface implementation using Typer</p>"},{"location":"api/#thumbnail-extraction","title":"Thumbnail Extraction","text":"<p>SSIM-based thumbnail matching and extraction</p>"},{"location":"api/#quick-api-example","title":"Quick API Example","text":"<pre><code>from loups import Loups\n\n# Create Loups instance\nloups = Loups(\n    video_path=\"game_video.mp4\",\n    template_path=\"template.png\"\n)\n\n# Scan for chapters\nchapters = loups.scan()\n\n# Print results\nfor chapter in chapters:\n    print(f\"{chapter.timestamp} {chapter.title}\")\n</code></pre>"},{"location":"api/#installation","title":"Installation","text":"<pre><code>pip install loups\n</code></pre> <p>Then import in your Python code:</p> <pre><code>from loups import Loups\nfrom loups.cli import app\nfrom loups.thumbnail_extractor import extract_thumbnail\n</code></pre>"},{"location":"api/#module-links","title":"Module Links","text":"Module Description Link <code>loups.loups</code> Main Loups class Documentation <code>loups.cli</code> CLI application Documentation <code>loups.thumbnail_extractor</code> Thumbnail extraction Documentation <code>loups.match_template_scan</code> Template matching API docs <code>loups.frame_utils</code> Frame utilities API docs <code>loups.geometry</code> Geometry helpers API docs"},{"location":"api/#common-use-cases","title":"Common Use Cases","text":""},{"location":"api/#batch-processing","title":"Batch Processing","text":"<pre><code>from pathlib import Path\nfrom loups import Loups\n\nvideos = Path(\"videos\").glob(\"*.mp4\")\n\nfor video in videos:\n    loups = Loups(\n        video_path=str(video),\n        template_path=\"template.png\"\n    )\n\n    chapters = loups.scan()\n\n    # Save chapters\n    output = video.with_suffix(\".txt\")\n    output.write_text(\"\\n\".join([\n        f\"{ch.timestamp} {ch.title}\"\n        for ch in chapters\n    ]))\n</code></pre>"},{"location":"api/#custom-processing","title":"Custom Processing","text":"<pre><code>from loups import Loups\n\nloups = Loups(\n    video_path=\"video.mp4\",\n    template_path=\"template.png\",\n    threshold=0.8,  # Stricter matching\n    log_level=\"DEBUG\"\n)\n\n# Access internal data\nfor frame_num, match in loups.matches.items():\n    print(f\"Frame {frame_num}: {match.confidence}\")\n</code></pre>"},{"location":"api/#integration-with-other-tools","title":"Integration with Other Tools","text":"<pre><code>from loups import Loups\nimport json\n\nloups = Loups(\"video.mp4\", \"template.png\")\nchapters = loups.scan()\n\n# Export as JSON\nchapters_json = json.dumps([\n    {\n        \"timestamp\": ch.timestamp,\n        \"title\": ch.title,\n        \"frame_number\": ch.frame_number\n    }\n    for ch in chapters\n], indent=2)\n\nprint(chapters_json)\n</code></pre>"},{"location":"api/#api-questions","title":"API Questions","text":"Can I use Loups without the CLI? <p>Yes! The Python API is fully featured:</p> <pre><code>from loups import Loups\n\nloups = Loups(\"video.mp4\", \"template.png\")\nchapters = loups.scan()\n</code></pre> How do I access raw OCR results? <p>Access the internal OCR data:</p> <pre><code>loups = Loups(\"video.mp4\", \"template.png\")\nloups.scan()\n\n# Access OCR results for each match\nfor frame_num, ocr_result in loups.ocr_results.items():\n    print(f\"Frame {frame_num}: {ocr_result}\")\n</code></pre> Can I customize the OCR engine? <p>Currently Loups uses EasyOCR. You can configure:</p> <pre><code>loups = Loups(\n    video_path=\"video.mp4\",\n    template_path=\"template.png\",\n    ocr_languages=['en'],  # Languages\n    ocr_confidence=0.6     # Confidence threshold\n)\n</code></pre>"},{"location":"api/#related-documentation","title":"Related Documentation","text":"<ul> <li> Quick Start - Get started with Loups</li> <li> CLI Reference - Command-line usage</li> <li> How It Works - Technical details</li> </ul>"},{"location":"api/cli/","title":"CLI Module","text":"<p>Command-line interface implementation using Typer and Rich.</p>"},{"location":"api/cli/#module-documentation","title":"Module Documentation","text":""},{"location":"api/cli/#loups.cli","title":"cli","text":"<p>Command-line interface for the loups package.</p>"},{"location":"api/cli/#loups.cli-classes","title":"Classes","text":""},{"location":"api/cli/#loups.cli-functions","title":"Functions","text":""},{"location":"api/cli/#loups.cli.get_default_template","title":"get_default_template","text":"<pre><code>get_default_template() -&gt; Path\n</code></pre> <p>Get path to the default bundled template image.</p> <p>Returns:</p> Type Description <code>Path</code> <p>Path to the bundled template_solid.png file.</p> <p>Raises:</p> Type Description <code>FileNotFoundError</code> <p>If the default template cannot be located.</p> Source code in <code>loups/cli.py</code> <pre><code>def get_default_template() -&gt; Path:\n    \"\"\"Get path to the default bundled template image.\n\n    Returns:\n        Path to the bundled template_solid.png file.\n\n    Raises:\n        FileNotFoundError: If the default template cannot be located.\n    \"\"\"\n    try:\n        # Use importlib.resources to locate the bundled template\n        template_path = files(\"loups\").joinpath(\"data/template_solid.png\")\n        # For Python 3.9+, we need to use as_file context manager\n        # but for simpler usage, we'll convert to string path\n        return Path(str(template_path))\n    except Exception:\n        # Fallback for development/testing\n        fallback = Path(__file__).parent / \"data\" / \"template_solid.png\"\n        if fallback.exists():\n            return fallback\n        raise FileNotFoundError(\n            \"Could not locate default template. \"\n            \"Please specify a template with --template\"\n        )\n</code></pre>"},{"location":"api/cli/#loups.cli.get_default_thumbnail_template","title":"get_default_thumbnail_template","text":"<pre><code>get_default_thumbnail_template() -&gt; Path\n</code></pre> <p>Get path to the default bundled thumbnail template image.</p> <p>Returns:</p> Type Description <code>Path</code> <p>Path to the bundled thumbnail_template.png file.</p> <p>Raises:</p> Type Description <code>FileNotFoundError</code> <p>If the default thumbnail template cannot be located.</p> Source code in <code>loups/cli.py</code> <pre><code>def get_default_thumbnail_template() -&gt; Path:\n    \"\"\"Get path to the default bundled thumbnail template image.\n\n    Returns:\n        Path to the bundled thumbnail_template.png file.\n\n    Raises:\n        FileNotFoundError: If the default thumbnail template cannot be located.\n    \"\"\"\n    try:\n        # Use importlib.resources to locate the bundled thumbnail template\n        template_path = files(\"loups\").joinpath(\"data/thumbnail_template.png\")\n        return Path(str(template_path))\n    except Exception:\n        # Fallback for development/testing\n        fallback = Path(__file__).parent / \"data\" / \"thumbnail_template.png\"\n        if fallback.exists():\n            return fallback\n        raise FileNotFoundError(\n            \"Could not locate default thumbnail template. \"\n            \"Please specify a template with --thumbnail-template or \"\n            \"add thumbnail_template.png to loups/data/\"\n        )\n</code></pre>"},{"location":"api/cli/#loups.cli.setup_logging","title":"setup_logging","text":"<pre><code>setup_logging(\n    log_path: Optional[Path] = None,\n    quiet: bool = False,\n    debug: bool = False,\n) -&gt; None\n</code></pre> <p>Configure logging with file rotation and error output.</p> <p>Parameters:</p> Name Type Description Default <code>log_path</code> <code>Optional[Path]</code> <p>Optional path for log file. If None, file logging is disabled.</p> <code>None</code> <code>quiet</code> <code>bool</code> <p>If True, suppress non-error console output.</p> <code>False</code> <code>debug</code> <code>bool</code> <p>If True, set file log level to DEBUG instead of INFO.</p> <code>False</code> Note <p>File logs rotate at 10MB with 3 backup files. Errors always go to stderr regardless of quiet mode.</p> Source code in <code>loups/cli.py</code> <pre><code>def setup_logging(\n    log_path: Optional[Path] = None, quiet: bool = False, debug: bool = False\n) -&gt; None:\n    \"\"\"Configure logging with file rotation and error output.\n\n    Args:\n        log_path: Optional path for log file. If None, file logging is disabled.\n        quiet: If True, suppress non-error console output.\n        debug: If True, set file log level to DEBUG instead of INFO.\n\n    Note:\n        File logs rotate at 10MB with 3 backup files.\n        Errors always go to stderr regardless of quiet mode.\n    \"\"\"\n    # Configure root logger\n    root_logger = logging.getLogger()\n    root_logger.setLevel(logging.DEBUG)\n\n    # Create rotating file handler if log_path is provided\n    if log_path is not None:\n        file_handler = RotatingFileHandler(\n            log_path,\n            maxBytes=10 * 1024 * 1024,  # 10MB\n            backupCount=3,\n        )\n        # Set file log level based on debug flag\n        file_handler.setLevel(logging.DEBUG if debug else logging.INFO)\n        file_formatter = logging.Formatter(\n            \"%(asctime)s - %(name)s - %(levelname)s - %(message)s\"\n        )\n        file_handler.setFormatter(file_formatter)\n        root_logger.addHandler(file_handler)\n\n    # Always log errors to stderr (even in quiet mode)\n    console_handler = logging.StreamHandler(sys.stderr)\n    console_handler.setLevel(logging.ERROR)\n    console_formatter = logging.Formatter(\"%(levelname)s: %(message)s\")\n    console_handler.setFormatter(console_formatter)\n    root_logger.addHandler(console_handler)\n</code></pre>"},{"location":"api/cli/#loups.cli.format_elapsed_time","title":"format_elapsed_time","text":"<pre><code>format_elapsed_time(seconds: float) -&gt; str\n</code></pre> <p>Format elapsed time as HH:MM:SS or MM:SS.</p> <p>Parameters:</p> Name Type Description Default <code>seconds</code> <code>float</code> <p>Elapsed time in seconds.</p> required <p>Returns:</p> Type Description <code>str</code> <p>Formatted time string (MM:SS if &lt; 1 hour, otherwise HH:MM:SS).</p> <p>Examples:</p> <pre><code>format_elapsed_time(65)    # \"01:05\"\nformat_elapsed_time(3665)  # \"01:01:05\"\n</code></pre> Source code in <code>loups/cli.py</code> <pre><code>def format_elapsed_time(seconds: float) -&gt; str:\n    \"\"\"Format elapsed time as HH:MM:SS or MM:SS.\n\n    Args:\n        seconds: Elapsed time in seconds.\n\n    Returns:\n        Formatted time string (MM:SS if &lt; 1 hour, otherwise HH:MM:SS).\n\n    Examples:\n        ```python\n        format_elapsed_time(65)    # \"01:05\"\n        format_elapsed_time(3665)  # \"01:01:05\"\n        ```\n    \"\"\"\n    hours = int(seconds // 3600)\n    minutes = int((seconds % 3600) // 60)\n    secs = int(seconds % 60)\n\n    if hours &gt; 0:\n        return f\"{hours:02d}:{minutes:02d}:{secs:02d}\"\n    else:\n        return f\"{minutes:02d}:{secs:02d}\"\n</code></pre>"},{"location":"api/cli/#loups.cli.create_progress_display","title":"create_progress_display","text":"<pre><code>create_progress_display(\n    elapsed: float,\n    batter_count: int,\n    spinner_state: int,\n    percent: Optional[float] = None,\n    last_batter: Optional[str] = None,\n) -&gt; Text\n</code></pre> <p>Create animated progress display with softball animation.</p> <p>Parameters:</p> Name Type Description Default <code>elapsed</code> <code>float</code> <p>Elapsed time in seconds.</p> required <code>batter_count</code> <code>int</code> <p>Number of batters found so far.</p> required <code>spinner_state</code> <code>int</code> <p>Current animation frame number.</p> required <code>percent</code> <code>Optional[float]</code> <p>Optional scan completion percentage.</p> <code>None</code> <code>last_batter</code> <code>Optional[str]</code> <p>Optional name of most recently found batter.</p> <code>None</code> <p>Returns:</p> Type Description <code>Text</code> <p>Rich Text object with animated progress display.</p> Source code in <code>loups/cli.py</code> <pre><code>def create_progress_display(\n    elapsed: float,\n    batter_count: int,\n    spinner_state: int,\n    percent: Optional[float] = None,\n    last_batter: Optional[str] = None,\n) -&gt; Text:\n    \"\"\"Create animated progress display with softball animation.\n\n    Args:\n        elapsed: Elapsed time in seconds.\n        batter_count: Number of batters found so far.\n        spinner_state: Current animation frame number.\n        percent: Optional scan completion percentage.\n        last_batter: Optional name of most recently found batter.\n\n    Returns:\n        Rich Text object with animated progress display.\n    \"\"\"\n    # Softball moving left and right (bouncing animation)\n    positions = [\"\ud83e\udd4e   \", \" \ud83e\udd4e  \", \"  \ud83e\udd4e \", \"   \ud83e\udd4e\", \"  \ud83e\udd4e \", \" \ud83e\udd4e  \"]\n    softball_display = positions[spinner_state % len(positions)]\n\n    # Build the display text\n    text = Text()\n    text.append(softball_display, style=\"bold yellow\")\n    text.append(\" Scanning batters... \", style=\"bold\")\n\n    # Show percentage if available\n    if percent is not None:\n        text.append(f\"{percent:.1f}%\", style=\"bold cyan\")\n        text.append(\" | \", style=\"dim\")\n\n    text.append(\"Found \", style=\"dim\")\n    text.append(f\"{batter_count}\", style=\"bold green\")\n    text.append(f\" batter{'s' if batter_count != 1 else ''}\", style=\"dim\")\n\n    # Show last batter found\n    if last_batter:\n        text.append(\"\\n\")\n        text.append(\"\ud83c\udfdf\ufe0f     Found: \", style=\"dim\")\n        text.append(last_batter, style=\"bold green\")\n\n    return text\n</code></pre>"},{"location":"api/cli/#loups.cli.create_thumbnail_progress_display","title":"create_thumbnail_progress_display","text":"<pre><code>create_thumbnail_progress_display(\n    spinner_state: int,\n) -&gt; Text\n</code></pre> <p>Create animated progress display for thumbnail extraction.</p> <p>Parameters:</p> Name Type Description Default <code>spinner_state</code> <code>int</code> <p>Current animation frame number.</p> required <p>Returns:</p> Type Description <code>Text</code> <p>Rich Text object with animated progress display.</p> Source code in <code>loups/cli.py</code> <pre><code>def create_thumbnail_progress_display(\n    spinner_state: int,\n) -&gt; Text:\n    \"\"\"Create animated progress display for thumbnail extraction.\n\n    Args:\n        spinner_state: Current animation frame number.\n\n    Returns:\n        Rich Text object with animated progress display.\n    \"\"\"\n    positions = [\"\ud83e\udd4e   \", \" \ud83e\udd4e  \", \"  \ud83e\udd4e \", \"   \ud83e\udd4e\", \"  \ud83e\udd4e \", \" \ud83e\udd4e  \"]\n    softball_display = positions[spinner_state % len(positions)]\n\n    text = Text()\n    text.append(softball_display, style=\"bold yellow\")\n    text.append(\" Extracting thumbnail...\", style=\"bold\")\n    return text\n</code></pre>"},{"location":"api/cli/#loups.cli.thumbnail","title":"thumbnail","text":"<pre><code>thumbnail(\n    ctx: Context,\n    thumbnail_template: Optional[Path] = Option(\n        None,\n        \"--thumbnail-template\",\n        help=\"Path to thumbnail template image (defaults to bundled template)\",\n    ),\n    thumbnail_output: Optional[Path] = Option(\n        None,\n        \"--thumbnail-output\",\n        help=\"Output path for thumbnail (default: &lt;video&gt;-thumbnail.jpg in cwd)\",\n    ),\n    thumbnail_scan_duration: int = Option(\n        120,\n        \"--thumbnail-scan-duration\",\n        help=\"Maximum seconds to scan from video start\",\n    ),\n    thumbnail_threshold: float = Option(\n        0.35,\n        \"--thumbnail-threshold\",\n        min=0.0,\n        max=1.0,\n        help=\"Minimum SSIM score to accept (0.0-1.0)\",\n    ),\n    thumbnail_frames_per_second: int = Option(\n        3,\n        \"--thumbnail-frames-per-second\",\n        min=1,\n        help=\"Frame sampling rate (frames to check per second)\",\n    ),\n    quiet: bool = Option(\n        False,\n        \"--quiet\",\n        \"-q\",\n        help=\"Suppress progress display and output\",\n    ),\n    log: Optional[str] = Option(\n        None,\n        \"--log\",\n        \"-l\",\n        is_flag=False,\n        flag_value=\"loups.log\",\n        help=\"Enable logging. Use without argument for default 'loups.log', or provide a path for custom location. Logs rotate at 10MB, keeps 3 backups.\",\n    ),\n    debug: bool = Option(\n        False,\n        \"--debug\",\n        \"-d\",\n        help=\"Enable DEBUG level logging to file (default is INFO)\",\n    ),\n) -&gt; None\n</code></pre> <p>Extract thumbnail from video using SSIM-based template matching.</p> <p>Scan video frames from the beginning to find a frame matching the template. Uses Structural Similarity Index (SSIM) for accurate frame matching. Stops at first match above threshold for efficiency.</p> <p>Examples:</p> <p>Extract with default template: <pre><code>loups video.mp4 thumbnail\n</code></pre></p> <p>Custom template and output: <pre><code>loups video.mp4 thumbnail --thumbnail-template custom.png             --thumbnail-output thumb.jpg\n</code></pre></p> Source code in <code>loups/cli.py</code> <pre><code>@app.command()\ndef thumbnail(\n    ctx: typer.Context,\n    thumbnail_template: Optional[Path] = typer.Option(  # noqa: B008\n        None,\n        \"--thumbnail-template\",\n        help=\"Path to thumbnail template image (defaults to bundled template)\",\n    ),\n    thumbnail_output: Optional[Path] = typer.Option(  # noqa: B008\n        None,\n        \"--thumbnail-output\",\n        help=\"Output path for thumbnail (default: &lt;video&gt;-thumbnail.jpg in cwd)\",\n    ),\n    thumbnail_scan_duration: int = typer.Option(  # noqa: B008\n        120,\n        \"--thumbnail-scan-duration\",\n        help=\"Maximum seconds to scan from video start\",\n    ),\n    thumbnail_threshold: float = typer.Option(  # noqa: B008\n        0.35,\n        \"--thumbnail-threshold\",\n        min=0.0,\n        max=1.0,\n        help=\"Minimum SSIM score to accept (0.0-1.0)\",\n    ),\n    thumbnail_frames_per_second: int = typer.Option(  # noqa: B008\n        3,\n        \"--thumbnail-frames-per-second\",\n        min=1,\n        help=\"Frame sampling rate (frames to check per second)\",\n    ),\n    quiet: bool = typer.Option(  # noqa: B008\n        False,\n        \"--quiet\",\n        \"-q\",\n        help=\"Suppress progress display and output\",\n    ),\n    log: Optional[str] = typer.Option(  # noqa: B008\n        None,\n        \"--log\",\n        \"-l\",\n        is_flag=False,\n        flag_value=\"loups.log\",\n        help=(\n            \"Enable logging. Use without argument for default 'loups.log', \"\n            \"or provide a path for custom location. \"\n            \"Logs rotate at 10MB, keeps 3 backups.\"\n        ),\n    ),\n    debug: bool = typer.Option(  # noqa: B008\n        False,\n        \"--debug\",\n        \"-d\",\n        help=\"Enable DEBUG level logging to file (default is INFO)\",\n    ),\n) -&gt; None:\n    \"\"\"Extract thumbnail from video using SSIM-based template matching.\n\n    Scan video frames from the beginning to find a frame matching the template.\n    Uses Structural Similarity Index (SSIM) for accurate frame matching.\n    Stops at first match above threshold for efficiency.\n\n    Examples:\n        Extract with default template:\n        ```bash\n        loups video.mp4 thumbnail\n        ```\n\n        Custom template and output:\n        ```bash\n        loups video.mp4 thumbnail --thumbnail-template custom.png \\\n            --thumbnail-output thumb.jpg\n        ```\n    \"\"\"\n    # Get video from parent context\n    video = ctx.parent.params[\"video\"]\n    # Ensure video is a Path object (defensive programming)\n    if not isinstance(video, Path):\n        video = Path(video)\n\n    # Set up logging\n    if log is not None:\n        log_path = Path(log)\n    else:\n        log_path = None\n    setup_logging(log_path, quiet, debug)\n\n    # Use shared helper function with fatal error handling\n    _run_thumbnail_extraction(\n        video=video,\n        template=thumbnail_template,\n        output=thumbnail_output,\n        threshold=thumbnail_threshold,\n        scan_duration=thumbnail_scan_duration,\n        frames_per_second=thumbnail_frames_per_second,\n        quiet=quiet,\n        is_fatal_on_error=True,  # Exit on errors (standalone command)\n    )\n</code></pre>"},{"location":"api/cli/#loups.cli.callback","title":"callback","text":"<pre><code>callback(\n    ctx: Context,\n    video: Path = Argument(\n        ..., help=\"Path to the video file to scan\"\n    ),\n    template: Optional[Path] = Option(\n        None,\n        \"--template\",\n        \"-t\",\n        help=\"Path to template image (defaults to bundled template)\",\n    ),\n    log: Optional[str] = Option(\n        None,\n        \"--log\",\n        \"-l\",\n        is_flag=False,\n        flag_value=\"loups.log\",\n        help=\"Enable logging. Use without argument for default 'loups.log', or provide a path for custom location. Logs rotate at 10MB, keeps 3 backups.\",\n    ),\n    output: Optional[Path] = Option(\n        None,\n        \"--output\",\n        \"-o\",\n        help=\"Save results to file (YouTube chapter format)\",\n    ),\n    quiet: bool = Option(\n        False,\n        \"--quiet\",\n        \"-q\",\n        help=\"Suppress progress display and output (errors still go to stderr)\",\n    ),\n    debug: bool = Option(\n        False,\n        \"--debug\",\n        \"-d\",\n        help=\"Enable DEBUG level logging to file (default is INFO)\",\n    ),\n    extract_thumbnail: bool = Option(\n        False,\n        \"--extract-thumbnail\",\n        help=\"Extract thumbnail during chapter scan\",\n    ),\n    thumbnail_template: Optional[Path] = Option(\n        None,\n        \"--thumbnail-template\",\n        help=\"Path to thumbnail template (defaults to bundled template)\",\n    ),\n    thumbnail_output: Optional[Path] = Option(\n        None,\n        \"--thumbnail-output\",\n        help=\"Output path for thumbnail (default: &lt;video&gt;-thumbnail.jpg in cwd)\",\n    ),\n    thumbnail_threshold: float = Option(\n        0.35,\n        \"--thumbnail-threshold\",\n        min=0.0,\n        max=1.0,\n        help=\"Minimum SSIM score for thumbnail (0.0-1.0)\",\n    ),\n    thumbnail_scan_duration: int = Option(\n        120,\n        \"--thumbnail-scan-duration\",\n        help=\"Maximum seconds to scan for thumbnail\",\n    ),\n    thumbnail_frames_per_second: int = Option(\n        3,\n        \"--thumbnail-frames-per-second\",\n        min=1,\n        help=\"Frame sampling rate for thumbnail extraction\",\n    ),\n) -&gt; None\n</code></pre> <p>Scan video to extract batter information and generate YouTube chapters.</p> <p>Main command for processing Lights Out HB fastpitch game videos (or any video with consistent identifying frames). Detects batters using template matching and extracts names via OCR. Outputs YouTube-compatible chapter timestamps.</p> <p>Examples:</p> <p>Basic scan with default template: <pre><code>loups game.mp4\n</code></pre></p> <p>Save chapters to file: <pre><code>loups -o chapters.txt game.mp4\n</code></pre></p> <p>Extract thumbnail and scan for batters: <pre><code>loups --extract-thumbnail --thumbnail-output thumb.jpg -o chapters.txt game.mp4\n</code></pre></p> <p>Use 'thumbnail' subcommand for standalone thumbnail extraction: <pre><code>loups game.mp4 thumbnail\n</code></pre></p> Source code in <code>loups/cli.py</code> <pre><code>@app.callback()\ndef callback(\n    ctx: typer.Context,\n    video: Path = typer.Argument(  # noqa: B008\n        ...,\n        help=\"Path to the video file to scan\",\n    ),\n    template: Optional[Path] = typer.Option(  # noqa: B008\n        None,\n        \"--template\",\n        \"-t\",\n        help=\"Path to template image (defaults to bundled template)\",\n    ),\n    log: Optional[str] = typer.Option(  # noqa: B008\n        None,\n        \"--log\",\n        \"-l\",\n        is_flag=False,\n        flag_value=\"loups.log\",\n        help=(\n            \"Enable logging. Use without argument for default 'loups.log', \"\n            \"or provide a path for custom location. \"\n            \"Logs rotate at 10MB, keeps 3 backups.\"\n        ),\n    ),\n    output: Optional[Path] = typer.Option(  # noqa: B008\n        None,\n        \"--output\",\n        \"-o\",\n        help=\"Save results to file (YouTube chapter format)\",\n    ),\n    quiet: bool = typer.Option(  # noqa: B008\n        False,\n        \"--quiet\",\n        \"-q\",\n        help=\"Suppress progress display and output (errors still go to stderr)\",\n    ),\n    debug: bool = typer.Option(  # noqa: B008\n        False,\n        \"--debug\",\n        \"-d\",\n        help=\"Enable DEBUG level logging to file (default is INFO)\",\n    ),\n    extract_thumbnail: bool = typer.Option(  # noqa: B008\n        False,\n        \"--extract-thumbnail\",\n        help=\"Extract thumbnail during chapter scan\",\n    ),\n    thumbnail_template: Optional[Path] = typer.Option(  # noqa: B008\n        None,\n        \"--thumbnail-template\",\n        help=\"Path to thumbnail template (defaults to bundled template)\",\n    ),\n    thumbnail_output: Optional[Path] = typer.Option(  # noqa: B008\n        None,\n        \"--thumbnail-output\",\n        help=\"Output path for thumbnail (default: &lt;video&gt;-thumbnail.jpg in cwd)\",\n    ),\n    thumbnail_threshold: float = typer.Option(  # noqa: B008\n        0.35,\n        \"--thumbnail-threshold\",\n        min=0.0,\n        max=1.0,\n        help=\"Minimum SSIM score for thumbnail (0.0-1.0)\",\n    ),\n    thumbnail_scan_duration: int = typer.Option(  # noqa: B008\n        120,\n        \"--thumbnail-scan-duration\",\n        help=\"Maximum seconds to scan for thumbnail\",\n    ),\n    thumbnail_frames_per_second: int = typer.Option(  # noqa: B008\n        3,\n        \"--thumbnail-frames-per-second\",\n        min=1,\n        help=\"Frame sampling rate for thumbnail extraction\",\n    ),\n) -&gt; None:\n    \"\"\"Scan video to extract batter information and generate YouTube chapters.\n\n    Main command for processing Lights Out HB fastpitch game videos (or any video\n    with consistent identifying frames). Detects batters using template matching\n    and extracts names via OCR. Outputs YouTube-compatible chapter timestamps.\n\n    Examples:\n        Basic scan with default template:\n        ```bash\n        loups game.mp4\n        ```\n\n        Save chapters to file:\n        ```bash\n        loups -o chapters.txt game.mp4\n        ```\n\n        Extract thumbnail and scan for batters:\n        ```bash\n        loups --extract-thumbnail --thumbnail-output thumb.jpg -o chapters.txt game.mp4\n        ```\n\n        Use 'thumbnail' subcommand for standalone thumbnail extraction:\n        ```bash\n        loups game.mp4 thumbnail\n        ```\n    \"\"\"\n    # If a subcommand was invoked, let it run\n    if ctx.invoked_subcommand is not None:\n        return\n\n    # No subcommand - run the default scan behavior\n    # Verify video exists\n    if not video.exists():\n        err_console.print(f\"[red]Error:[/red] Video file not found: {video}\")\n        raise typer.Exit(1)\n\n    # Determine log path\n    if log is not None:\n        log_path = Path(log)\n    else:\n        log_path = None\n\n    # Set up logging\n    setup_logging(log_path, quiet, debug)\n\n    # Detect if stdout is being piped/redirected\n    is_piped = not sys.stdout.isatty()\n\n    # Get template path\n    if template is None:\n        try:\n            template = get_default_template()\n        except FileNotFoundError as e:\n            err_console.print(f\"[red]Error:[/red] {e}\")\n            raise typer.Exit(1)\n\n    # Verify template exists\n    if not template.exists():\n        err_console.print(f\"[red]Error:[/red] Template file not found: {template}\")\n        raise typer.Exit(1)\n\n    # Show \"Scanning video:\" header at the top\n    show_progress = not quiet and not is_piped\n    if show_progress:\n        console.print(f\"[bold]Scanning video:[/bold] {video}\")\n        console.print()\n\n    # Extract thumbnail if requested\n    if extract_thumbnail:\n        # Use shared helper function with non-fatal error handling\n        _run_thumbnail_extraction(\n            video=video,\n            template=thumbnail_template,\n            output=thumbnail_output,\n            threshold=thumbnail_threshold,\n            scan_duration=thumbnail_scan_duration,\n            frames_per_second=thumbnail_frames_per_second,\n            quiet=quiet,\n            is_fatal_on_error=False,  # Warnings only, continue on errors\n            show_header=False,  # Header already shown above\n        )\n\n    # Progress tracking\n    start_time = time.time()\n    batter_count = 0\n    spinner_state = 0\n    last_batter_name = None\n    progress_percent = 0.0\n\n    def on_batter_found(batter_info):\n        \"\"\"Handle callback when a new batter is found.\"\"\"\n        nonlocal batter_count, last_batter_name\n        batter_count += 1\n        last_batter_name = batter_info.batter_name\n\n    def on_progress(frames_processed, total_frames):\n        \"\"\"Update progress percentage on each frame processed.\"\"\"\n        nonlocal progress_percent\n        if total_frames &gt; 0:\n            progress_percent = (frames_processed / total_frames) * 100\n\n    # Initialize Loups with callback\n    try:\n        game = Loups(\n            str(video),\n            str(template),\n            on_batter_found=on_batter_found,\n            on_progress=on_progress,\n        )\n    except Exception as e:\n        err_console.print(f\"[red]Error:[/red] Failed to initialize scanner: {e}\")\n        raise typer.Exit(1)\n\n    # Run scan with progress display (disabled when piped or quiet)\n    if show_progress:\n        # Add separator if we just extracted a thumbnail\n        if extract_thumbnail:\n            console.print()\n\n        # Variables to track scan completion and errors\n        scan_complete = threading.Event()\n        scan_error = None\n\n        def run_scan():\n            \"\"\"Run the scan in a background thread.\"\"\"\n            nonlocal scan_error\n            try:\n                game.scan()\n            except Exception as e:\n                scan_error = e\n            finally:\n                scan_complete.set()\n\n        # Start scan in background thread\n        scan_thread = threading.Thread(target=run_scan, daemon=True)\n        scan_thread.start()\n\n        with Live(\n            create_progress_display(0, 0, 0, 0.0),\n            refresh_per_second=4,\n            console=console,\n        ) as live:\n            # Continuously update display while scan is running\n            while not scan_complete.is_set():\n                current_time = time.time()\n                elapsed = current_time - start_time\n                spinner_state += 1\n                live.update(\n                    create_progress_display(\n                        elapsed,\n                        batter_count,\n                        spinner_state,\n                        progress_percent,\n                        last_batter_name,\n                    )\n                )\n                time.sleep(0.25)  # Update every 250ms\n\n            # Final update\n            elapsed = time.time() - start_time\n            live.update(\n                create_progress_display(\n                    elapsed,\n                    batter_count,\n                    spinner_state,\n                    progress_percent,\n                    last_batter_name,\n                )\n            )\n\n        # Check for errors\n        if scan_error:\n            err_console.print(f\"\\n[red]Error:[/red] Scan failed: {scan_error}\")\n            raise typer.Exit(1)\n\n        console.print()\n        console.print(\n            f\"\ud83c\udfc6 [bold green]Scan complete![/bold green] \"\n            f\"Found {game.batter_count} batters \"\n            f\"in {format_elapsed_time(elapsed)}\"\n        )\n        console.print()\n    else:\n        # Quiet mode or piped output - just run the scan\n        try:\n            game.scan()\n        except Exception as e:\n            err_console.print(f\"[red]Error:[/red] Scan failed: {e}\")\n            raise typer.Exit(1)\n\n    # Get results using the display() method\n    results = game.batters.display()\n\n    # Output to stdout (unless quiet)\n    if not quiet:\n        if is_piped:\n            # When piped, output plain text to stdout (no formatting)\n            print(results)\n        else:\n            # Interactive terminal: show formatted output\n            console.print(\"[bold]YouTube Chapters:[/bold]\")\n            console.print(results)\n\n    # Output to file if specified\n    if output:\n        try:\n            output.write_text(results)\n            if show_progress:\n                console.print()\n                console.print(f\"\u2713 Results saved to: [cyan]{output}[/cyan]\")\n        except Exception as e:\n            err_console.print(f\"[red]Error:[/red] Failed to write output file: {e}\")\n            raise typer.Exit(1)\n</code></pre>"},{"location":"api/cli/#cli-architecture","title":"CLI Architecture","text":"<p>The Loups CLI is built with:</p> <ul> <li>Typer - Modern CLI framework</li> <li>Rich - Beautiful terminal output</li> <li>Subcommands - Main command + thumbnail extraction</li> </ul> <pre><code>graph TD\n    A[loups CLI] --&gt; B[Main Command]\n    A --&gt; C[Thumbnail Subcommand]\n\n    B --&gt; B1[Parse Arguments]\n    B1 --&gt; B2[Initialize Loups]\n    B2 --&gt; B3[Scan Video]\n    B3 --&gt; B4[Display/Save Results]\n\n    C --&gt; C1[Parse Arguments]\n    C1 --&gt; C2[Extract Thumbnail]\n    C2 --&gt; C3[Save JPEG]\n\n    style A fill:#00ffff,stroke:#000,color:#000\n    style B fill:#00b8d4,stroke:#000,color:#fff\n    style C fill:#00b8d4,stroke:#000,color:#fff\n    style B4 fill:#00ffff,stroke:#000,color:#000\n    style C3 fill:#00ffff,stroke:#000,color:#000</code></pre>"},{"location":"api/cli/#customizing-the-cli","title":"Customizing the CLI","text":""},{"location":"api/cli/#extending-commands","title":"Extending Commands","text":"<p>You can build on top of the Loups CLI:</p> <pre><code>from loups.cli import app\nimport typer\n\n@app.command()\ndef batch(\n    directory: str = typer.Argument(..., help=\"Directory with videos\"),\n    template: str = typer.Option(None, \"-t\", \"--template\")\n):\n    \"\"\"Process all videos in a directory.\"\"\"\n    from pathlib import Path\n    from loups import Loups\n\n    video_dir = Path(directory)\n\n    for video in video_dir.glob(\"*.mp4\"):\n        print(f\"Processing {video.name}...\")\n\n        loups = Loups(\n            video_path=str(video),\n            template_path=template\n        )\n\n        chapters = loups.scan()\n\n        # Save output\n        output = video.with_suffix(\".txt\")\n        with open(output, \"w\") as f:\n            for ch in chapters:\n                f.write(f\"{ch.timestamp} {ch.title}\\n\")\n\nif __name__ == \"__main__\":\n    app()\n</code></pre>"},{"location":"api/cli/#custom-progress-display","title":"Custom Progress Display","text":"<p>Replace the default progress bar:</p> <pre><code>from loups import Loups\nfrom rich.progress import Progress, SpinnerColumn, TextColumn\n\nclass CustomLoups(Loups):\n    def scan(self):\n        with Progress(\n            SpinnerColumn(),\n            TextColumn(\"[progress.description]{task.description}\"),\n            transient=True\n        ) as progress:\n            task = progress.add_task(\"Scanning...\", total=None)\n\n            # Your custom processing\n            results = super().scan()\n\n            progress.update(task, completed=True)\n            return results\n</code></pre>"},{"location":"api/cli/#output-formatting","title":"Output Formatting","text":""},{"location":"api/cli/#custom-chapter-format","title":"Custom Chapter Format","text":"<pre><code>from loups import Loups\n\nloups = Loups(\"video.mp4\", \"template.png\")\nchapters = loups.scan()\n\n# Custom format\nfor i, ch in enumerate(chapters, 1):\n    print(f\"{i}. [{ch.timestamp}] {ch.title}\")\n\n# JSON format\nimport json\noutput = json.dumps([\n    {\"time\": ch.timestamp, \"title\": ch.title}\n    for ch in chapters\n], indent=2)\nprint(output)\n\n# Markdown format\nprint(\"## Chapters\\n\")\nfor ch in chapters:\n    print(f\"- **{ch.timestamp}** - {ch.title}\")\n</code></pre>"},{"location":"api/cli/#automation-examples","title":"Automation Examples","text":""},{"location":"api/cli/#shell-script-integration","title":"Shell Script Integration","text":"<pre><code>#!/bin/bash\n# process_videos.sh\n\nfor video in videos/*.mp4; do\n  echo \"Processing: $video\"\n\n  # Run Loups\n  loups -q -o \"${video%.mp4}.txt\" \"$video\"\n\n  # Check exit code\n  if [ $? -eq 0 ]; then\n    echo \"\u2705 Success: $video\"\n  else\n    echo \"\u274c Failed: $video\"\n  fi\ndone\n</code></pre>"},{"location":"api/cli/#python-automation","title":"Python Automation","text":"<pre><code>import subprocess\nfrom pathlib import Path\n\nvideos = Path(\"videos\").glob(\"*.mp4\")\n\nfor video in videos:\n    output = video.with_suffix(\".txt\")\n\n    # Run Loups CLI\n    result = subprocess.run([\n        \"loups\",\n        \"-q\",\n        \"-o\", str(output),\n        str(video)\n    ], capture_output=True, text=True)\n\n    if result.returncode == 0:\n        print(f\"\u2705 {video.name}\")\n    else:\n        print(f\"\u274c {video.name}: {result.stderr}\")\n</code></pre>"},{"location":"api/cli/#cli-development","title":"CLI Development","text":""},{"location":"api/cli/#running-from-source","title":"Running from Source","text":"<pre><code># Install in development mode\npip install -e .\n\n# Or use Python module\npython -m loups.cli --help\n</code></pre>"},{"location":"api/cli/#testing-cli-commands","title":"Testing CLI Commands","text":"<pre><code>from typer.testing import CliRunner\nfrom loups.cli import app\n\nrunner = CliRunner()\n\ndef test_main_command():\n    result = runner.invoke(app, [\"--help\"])\n    assert result.exit_code == 0\n    assert \"video\" in result.stdout.lower()\n\ndef test_thumbnail_command():\n    result = runner.invoke(app, [\n        \"test.mp4\",\n        \"thumbnail\",\n        \"--thumbnail-output\", \"thumb.jpg\"\n    ])\n    assert result.exit_code == 0\n</code></pre>"},{"location":"api/cli/#command-reference","title":"Command Reference","text":"<p>For complete CLI usage documentation, see:</p> <ul> <li> CLI Reference - All command options</li> <li> Quick Start - Usage examples</li> </ul>"},{"location":"api/cli/#related","title":"Related","text":"<ul> <li> Loups Class - Core Python API</li> <li> Thumbnail Extraction - Thumbnail API</li> <li> CLI Reference Guide - User documentation</li> </ul>"},{"location":"api/loups/","title":"Loups Class","text":"<p>Main class for video chapter generation using template matching and OCR.</p>"},{"location":"api/loups/#class-documentation","title":"Class Documentation","text":""},{"location":"api/loups/#loups.loups.Loups","title":"Loups","text":"<pre><code>Loups(\n    scannable: Union[str, Path],\n    template: Union[str, Path],\n    method: str = \"TM_CCOEFF_NORMED\",\n    threshold: Optional[float] = None,\n    resolution: int = 3,\n    on_batter_found: Optional[\n        Callable[[FrameBatterInfo], None]\n    ] = None,\n    on_progress: Optional[\n        Callable[[int, int], None]\n    ] = None,\n)\n</code></pre> <p>Extract batter information from Lights Out HB fastpitch videos.</p> <p>Initialize Loups video scanner.</p> <p>Parameters:</p> Name Type Description Default <code>scannable</code> <code>Union[str, Path]</code> <p>Path to video file to scan.</p> required <code>template</code> <code>Union[str, Path]</code> <p>Path to template image used to identify batters.</p> required <code>method</code> <code>str</code> <p>Template matching method (TM_SQDIFF, TM_SQDIFF_NORMED, TM_CCORR, TM_CCORR_NORMED, TM_CCOEFF, TM_CCOEFF_NORMED). Default: TM_CCOEFF_NORMED.</p> <code>'TM_CCOEFF_NORMED'</code> <code>threshold</code> <code>Optional[float]</code> <p>Confidence threshold for accepting matches (0.0-1.0). Default varies by method.</p> <code>None</code> <code>resolution</code> <code>int</code> <p>Number of frames to analyze per second. Default: 3.</p> <code>3</code> <code>on_batter_found</code> <code>Optional[Callable[[FrameBatterInfo], None]]</code> <p>Optional callback when batter is found. Signature: callback(batter_info: FrameBatterInfo) -&gt; None</p> <code>None</code> <code>on_progress</code> <code>Optional[Callable[[int, int], None]]</code> <p>Optional callback for progress updates. Signature: callback(frames_processed: int, total_frames: int) -&gt; None</p> <code>None</code> <p>Examples:</p> <pre><code># Scan a video\ngame = Loups(\"game.mp4\", \"template.png\")\ngame.scan()\nprint(game.batters)\nprint(f\"Found {game.batter_count} batters\")\n\n# With callbacks\ndef on_found(batter_info):\n    print(f\"Found: {batter_info.batter_name}\")\n\ngame = Loups(\"game.mp4\", \"template.png\", on_batter_found=on_found)\n</code></pre> Source code in <code>loups/loups.py</code> <pre><code>def __init__(\n    self,\n    scannable: Union[str, Path],\n    template: Union[str, Path],\n    method: str = \"TM_CCOEFF_NORMED\",\n    threshold: Optional[float] = None,\n    resolution: int = 3,\n    on_batter_found: Optional[Callable[[FrameBatterInfo], None]] = None,\n    on_progress: Optional[Callable[[int, int], None]] = None,\n) -&gt; None:\n    \"\"\"Initialize Loups video scanner.\n\n    Args:\n        scannable: Path to video file to scan.\n        template: Path to template image used to identify batters.\n        method: Template matching method (TM_SQDIFF, TM_SQDIFF_NORMED,\n            TM_CCORR, TM_CCORR_NORMED, TM_CCOEFF, TM_CCOEFF_NORMED).\n            Default: TM_CCOEFF_NORMED.\n        threshold: Confidence threshold for accepting matches (0.0-1.0).\n            Default varies by method.\n        resolution: Number of frames to analyze per second. Default: 3.\n        on_batter_found: Optional callback when batter is found.\n            Signature: callback(batter_info: FrameBatterInfo) -&gt; None\n        on_progress: Optional callback for progress updates.\n            Signature: callback(frames_processed: int, total_frames: int) -&gt; None\n\n    Examples:\n        ```python\n        # Scan a video\n        game = Loups(\"game.mp4\", \"template.png\")\n        game.scan()\n        print(game.batters)\n        print(f\"Found {game.batter_count} batters\")\n\n        # With callbacks\n        def on_found(batter_info):\n            print(f\"Found: {batter_info.batter_name}\")\n\n        game = Loups(\"game.mp4\", \"template.png\", on_batter_found=on_found)\n        ```\n    \"\"\"\n    self._scannable = scannable\n    self._capture = self.create_capture()\n    self._frame_rate = self.get_frame_rate()\n    self.template = template\n    self._method = method\n    self.resolution = resolution\n    self.search_quadrant = \"bottomleft\"\n    self.on_batter_found = on_batter_found\n    self.on_progress = on_progress\n</code></pre>"},{"location":"api/loups/#loups.loups.Loups-attributes","title":"Attributes","text":""},{"location":"api/loups/#loups.loups.Loups.method","title":"method  <code>property</code>","text":"<pre><code>method: str\n</code></pre> <p>Get the template matching method name.</p> <p>Returns:</p> Type Description <code>str</code> <p>Template matching method string (e.g., \"TM_CCOEFF_NORMED\").</p>"},{"location":"api/loups/#loups.loups.Loups.scannable","title":"scannable  <code>property</code>","text":"<pre><code>scannable: Union[str, Path]\n</code></pre> <p>Get the path to the video file being scanned.</p> <p>Returns:</p> Type Description <code>Union[str, Path]</code> <p>Path to the video file.</p>"},{"location":"api/loups/#loups.loups.Loups.capture","title":"capture  <code>property</code>","text":"<pre><code>capture: VideoCapture\n</code></pre> <p>Get the OpenCV VideoCapture object.</p> <p>Returns:</p> Type Description <code>VideoCapture</code> <p>cv.VideoCapture instance for the video file.</p>"},{"location":"api/loups/#loups.loups.Loups.total_frames","title":"total_frames  <code>property</code>","text":"<pre><code>total_frames: float\n</code></pre> <p>Get total number of frames in the video.</p> <p>Returns:</p> Type Description <code>float</code> <p>Total frame count.</p>"},{"location":"api/loups/#loups.loups.Loups.frame_rate","title":"frame_rate  <code>property</code>","text":"<pre><code>frame_rate: float\n</code></pre> <p>Get the frame rate of the video.</p> <p>Returns:</p> Type Description <code>float</code> <p>Frame rate in frames per second (fps).</p>"},{"location":"api/loups/#loups.loups.Loups.template","title":"template  <code>property</code> <code>writable</code>","text":"<pre><code>template: ndarray\n</code></pre> <p>Get the template image as a numpy array.</p> <p>Returns:</p> Type Description <code>ndarray</code> <p>Grayscale template image as numpy ndarray.</p>"},{"location":"api/loups/#loups.loups.Loups-functions","title":"Functions","text":""},{"location":"api/loups/#loups.loups.Loups.get_reader","title":"get_reader  <code>classmethod</code>","text":"<pre><code>get_reader() -&gt; Reader\n</code></pre> <p>Get or initialize the shared EasyOCR reader.</p> <p>Lazy initialization pattern to avoid loading OCR models until needed.</p> <p>Returns:</p> Type Description <code>Reader</code> <p>Initialized easyocr.Reader instance for English text.</p> Source code in <code>loups/loups.py</code> <pre><code>@classmethod\ndef get_reader(cls) -&gt; easyocr.Reader:\n    \"\"\"Get or initialize the shared EasyOCR reader.\n\n    Lazy initialization pattern to avoid loading OCR models until needed.\n\n    Returns:\n        Initialized easyocr.Reader instance for English text.\n    \"\"\"\n    return easyocr.Reader([\"en\"]) if cls._reader is None else cls._reader\n</code></pre>"},{"location":"api/loups/#loups.loups.Loups.create_capture","title":"create_capture","text":"<pre><code>create_capture() -&gt; VideoCapture\n</code></pre> <p>Create OpenCV VideoCapture for the video file.</p> <p>Returns:</p> Type Description <code>VideoCapture</code> <p>cv.VideoCapture object for reading video frames.</p> Source code in <code>loups/loups.py</code> <pre><code>def create_capture(self) -&gt; cv.VideoCapture:\n    \"\"\"Create OpenCV VideoCapture for the video file.\n\n    Returns:\n        cv.VideoCapture object for reading video frames.\n    \"\"\"\n    return cv.VideoCapture(self.scannable)\n</code></pre>"},{"location":"api/loups/#loups.loups.Loups.get_frame_rate","title":"get_frame_rate","text":"<pre><code>get_frame_rate() -&gt; float\n</code></pre> <p>Get frame rate from video capture.</p> <p>Uses OpenCV CAP_PROP_FPS property.</p> <p>Returns:</p> Type Description <code>float</code> <p>Frame rate in frames per second.</p> Note <p>See https://docs.opencv.org/4.x/d4/d15/group__videoio__flags__base.html</p> Source code in <code>loups/loups.py</code> <pre><code>def get_frame_rate(self) -&gt; float:\n    \"\"\"Get frame rate from video capture.\n\n    Uses OpenCV CAP_PROP_FPS property.\n\n    Returns:\n        Frame rate in frames per second.\n\n    Note:\n        See https://docs.opencv.org/4.x/d4/d15/group__videoio__flags__base.html\n    \"\"\"\n    return self.capture.get(5)\n</code></pre>"},{"location":"api/loups/#loups.loups.Loups.frame_frequency","title":"frame_frequency","text":"<pre><code>frame_frequency() -&gt; int\n</code></pre> <p>Calculate frame sampling interval based on resolution.</p> <p>Returns:</p> Type Description <code>int</code> <p>Number of frames to skip between samples (e.g., 10 means every 10<sup>th</sup> frame).</p> Source code in <code>loups/loups.py</code> <pre><code>def frame_frequency(self) -&gt; int:\n    \"\"\"Calculate frame sampling interval based on resolution.\n\n    Returns:\n        Number of frames to skip between samples (e.g., 10 means every 10th frame).\n    \"\"\"\n    from .frame_utils import calculate_frame_frequency\n\n    return calculate_frame_frequency(self.frame_rate, self.resolution)\n</code></pre>"},{"location":"api/loups/#loups.loups.Loups.timestamp","title":"timestamp","text":"<pre><code>timestamp() -&gt; float\n</code></pre> <p>Get current video position timestamp.</p> <p>Returns:</p> Type Description <code>float</code> <p>Current timestamp in milliseconds.</p> Source code in <code>loups/loups.py</code> <pre><code>def timestamp(self) -&gt; float:\n    \"\"\"Get current video position timestamp.\n\n    Returns:\n        Current timestamp in milliseconds.\n    \"\"\"\n    return self.capture.get(0)\n</code></pre>"},{"location":"api/loups/#loups.loups.Loups.match_template_scan","title":"match_template_scan","text":"<pre><code>match_template_scan() -&gt; MatchTemplateScan\n</code></pre> <p>Perform template matching on current frame.</p> <p>Returns:</p> Type Description <code>MatchTemplateScan</code> <p>MatchTemplateScan object containing match results.</p> Source code in <code>loups/loups.py</code> <pre><code>def match_template_scan(self) -&gt; MatchTemplateScan:\n    \"\"\"Perform template matching on current frame.\n\n    Returns:\n        MatchTemplateScan object containing match results.\n    \"\"\"\n    scan = MatchTemplateScan(\n        image=cv.cvtColor(self.frame, cv.COLOR_BGR2GRAY),\n        template=self.template,\n        method=self.method,\n    )\n    return scan\n</code></pre>"},{"location":"api/loups/#loups.loups.Loups.new_batter","title":"new_batter","text":"<pre><code>new_batter(\n    res: list[FrameBatterInfo],\n    ms: float,\n    threshold: int = 2000,\n) -&gt; bool\n</code></pre> <p>Determine if a frame contains a new batter.</p> <p>Parameters:</p> Name Type Description Default <code>res</code> <code>list[FrameBatterInfo]</code> <p>List of previous FrameBatterInfo results.</p> required <code>ms</code> <code>float</code> <p>Current frame timestamp in milliseconds.</p> required <code>threshold</code> <code>int</code> <p>Minimum time in milliseconds between new batters.</p> <code>2000</code> <p>Returns:</p> Type Description <code>bool</code> <p>True if this frame represents a new batter, False otherwise.</p> Source code in <code>loups/loups.py</code> <pre><code>def new_batter(\n    self, res: list[FrameBatterInfo], ms: float, threshold: int = 2000\n) -&gt; bool:\n    \"\"\"Determine if a frame contains a new batter.\n\n    Args:\n        res: List of previous FrameBatterInfo results.\n        ms: Current frame timestamp in milliseconds.\n        threshold: Minimum time in milliseconds between new batters.\n\n    Returns:\n        True if this frame represents a new batter, False otherwise.\n    \"\"\"\n    new_batter_frame = self.prev_frame_is_not_batter(res)\n    logger.debug(f\"{new_batter_frame=}\")\n\n    prev_batter_frame_timestamp = self.prev_batter_frame_timestamp(res)\n    try:\n        time_since_prev_batter_frame = ms - prev_batter_frame_timestamp\n    except TypeError:\n        time_since_prev_batter_frame = None\n\n    return (\n        new_batter_frame and time_since_prev_batter_frame &gt; threshold\n        if time_since_prev_batter_frame is not None\n        else new_batter_frame\n    )\n</code></pre>"},{"location":"api/loups/#loups.loups.Loups.prev_batter_frame_timestamp","title":"prev_batter_frame_timestamp","text":"<pre><code>prev_batter_frame_timestamp(\n    frames: list[FrameBatterInfo],\n) -&gt; Optional[int]\n</code></pre> <p>Get timestamp of the most recent frame containing a batter.</p> <p>Parameters:</p> Name Type Description Default <code>frames</code> <code>list[FrameBatterInfo]</code> <p>List of FrameBatterInfo objects to search.</p> required <p>Returns:</p> Type Description <code>Optional[int]</code> <p>Timestamp in milliseconds of the last batter frame, or None</p> <code>Optional[int]</code> <p>if no batters found.</p> Source code in <code>loups/loups.py</code> <pre><code>def prev_batter_frame_timestamp(\n    self, frames: list[FrameBatterInfo]\n) -&gt; Optional[int]:\n    \"\"\"Get timestamp of the most recent frame containing a batter.\n\n    Args:\n        frames: List of FrameBatterInfo objects to search.\n\n    Returns:\n        Timestamp in milliseconds of the last batter frame, or None\n        if no batters found.\n    \"\"\"\n    try:\n        ts = max(frame.ms for frame in frames if frame.is_batter)\n    except ValueError:\n        ts = None\n    return ts\n</code></pre>"},{"location":"api/loups/#loups.loups.Loups.prev_frame_is_not_batter","title":"prev_frame_is_not_batter  <code>staticmethod</code>","text":"<pre><code>prev_frame_is_not_batter(res: list) -&gt; bool\n</code></pre> <p>Check if the previous frame did not contain a batter.</p> <p>Parameters:</p> Name Type Description Default <code>res</code> <code>list</code> <p>List of FrameBatterInfo results.</p> required <p>Returns:</p> Type Description <code>bool</code> <p>True if previous frame had no batter, False otherwise.</p> Source code in <code>loups/loups.py</code> <pre><code>@staticmethod\ndef prev_frame_is_not_batter(res: list) -&gt; bool:\n    \"\"\"Check if the previous frame did not contain a batter.\n\n    Args:\n        res: List of FrameBatterInfo results.\n\n    Returns:\n        True if previous frame had no batter, False otherwise.\n    \"\"\"\n    try:\n        prev_frame_is_batter = res[-1].is_batter\n    except IndexError:\n        prev_frame_is_batter = False\n    return not prev_frame_is_batter\n</code></pre>"},{"location":"api/loups/#loups.loups.Loups.batter_name","title":"batter_name","text":"<pre><code>batter_name(\n    match_top_left: Point, threshold: float = 0.2\n) -&gt; str\n</code></pre> <p>Extract batter name from frame using OCR.</p> <p>Parameters:</p> Name Type Description Default <code>match_top_left</code> <code>Point</code> <p>Top-left corner of template match location.</p> required <code>threshold</code> <code>float</code> <p>Minimum OCR confidence score to accept text (0.0-1.0).</p> <code>0.2</code> <p>Returns:</p> Type Description <code>str</code> <p>Extracted batter name with jersey number, or empty string if no text found.</p> <p>Examples:</p> <pre><code>name = game.batter_name(Point(100, 200))\n# Returns: \"Sarah Johnson #7\"\n</code></pre> Source code in <code>loups/loups.py</code> <pre><code>def batter_name(self, match_top_left: Point, threshold: float = 0.2) -&gt; str:\n    \"\"\"Extract batter name from frame using OCR.\n\n    Args:\n        match_top_left: Top-left corner of template match location.\n        threshold: Minimum OCR confidence score to accept text\n            (0.0-1.0).\n\n    Returns:\n        Extracted batter name with jersey number, or empty string if no text found.\n\n    Examples:\n        ```python\n        name = game.batter_name(Point(100, 200))\n        # Returns: \"Sarah Johnson #7\"\n        ```\n    \"\"\"\n    template_size = Size(*self.template.shape)\n\n    match_bottom_right = Point(\n        match_top_left.x + template_size.width,\n        match_top_left.y + template_size.height,\n    )\n\n    # Do not scan the template headshot\n    headshot = Size(width=215, height=None)\n\n    image_to_scan = self.frame[\n        match_top_left.y : match_bottom_right.y,\n        match_top_left.x + headshot.width : match_bottom_right.x,\n    ]\n\n    # Extract text\n    ocr = self.get_reader().readtext(image_to_scan)\n    logger.debug(f\"{ocr=}\")\n\n    # Filter by confidence threshold\n    filtered_ocr = [\n        (location, text, score)\n        for location, text, score in ocr\n        if score &gt; threshold\n    ]\n\n    # Sort by x-coordinate (left-to-right) using the leftmost point\n    # OCR location can be:\n    # - [[top-left], [top-right], [bottom-right], [bottom-left]]\n    #   (list of points)\n    # - (x1, y1, x2, y2) (tuple of coordinates)\n    # For left-to-right reading, sort by x-coordinate of leftmost point\n    def get_leftmost_x(item):\n        location = item[0]\n        # Check if it's a list of points or a flat tuple\n        if isinstance(location[0], (list, tuple)) and len(location[0]) &gt;= 2:\n            # List of points: [[x1, y1], [x2, y2], ...]\n            return min(point[0] for point in location)\n        else:\n            # Flat tuple: (x1, y1, x2, y2)\n            # x-coordinates are at even indices\n            return min(location[i] for i in range(0, len(location), 2))\n\n    sorted_ocr = sorted(filtered_ocr, key=get_leftmost_x)\n\n    # Extract just the text strings after sorting\n    text = [text for location, text, score in sorted_ocr]\n\n    # Extract jersey numbers and name parts from all elements\n    jersey_pattern = r\"#\\d+\"\n\n    # Collect all jersey numbers from all text elements\n    # (now in left-to-right order)\n    all_jerseys = [\n        jersey for item in text for jersey in re.findall(jersey_pattern, item)\n    ]\n\n    # Collect all non-jersey text parts\n    # (remove jerseys, normalize spaces, preserve left-to-right order)\n    all_name_parts = [\n        re.sub(r\"\\s+\", \" \", re.sub(jersey_pattern, \"\", item).strip())\n        for item in text\n    ]\n\n    # Filter out empty strings\n    all_name_parts = [part for part in all_name_parts if part]\n\n    # Combine: name parts first (in left-to-right order), then jersey numbers\n    result = \" \".join(all_name_parts + all_jerseys)\n    logger.debug(\n        f\"text={text}, all_name_parts={all_name_parts}, \"\n        f\"all_jerseys={all_jerseys}, result={result}\"\n    )\n\n    return result\n</code></pre>"},{"location":"api/loups/#loups.loups.Loups.scan","title":"scan","text":"<pre><code>scan() -&gt; Loups\n</code></pre> <p>Scan the video file to detect batters and extract information.</p> <p>Process video frames at the specified resolution, perform template matching, and use OCR to extract batter names. Results are stored in the <code>batters</code> attribute.</p> <p>Returns:</p> Type Description <code>Loups</code> <p>Self (for method chaining).</p> <p>Examples:</p> <pre><code>game = Loups(\"video.mp4\", \"template.png\")\ngame.scan()\nprint(f\"Found {game.batter_count} batters\")\nprint(game.batters)\n</code></pre> Source code in <code>loups/loups.py</code> <pre><code>def scan(self) -&gt; \"Loups\":\n    \"\"\"Scan the video file to detect batters and extract information.\n\n    Process video frames at the specified resolution, perform template matching,\n    and use OCR to extract batter names. Results are stored in the `batters`\n    attribute.\n\n    Returns:\n        Self (for method chaining).\n\n    Examples:\n        ```python\n        game = Loups(\"video.mp4\", \"template.png\")\n        game.scan()\n        print(f\"Found {game.batter_count} batters\")\n        print(game.batters)\n        ```\n    \"\"\"\n    frame_count = 0\n\n    # Initalize a list to collect FrameBatterInfo objects\n    frames = []\n    while True:\n        ret = self.capture.grab()\n\n        if not ret:\n            break\n\n        frame_count += 1\n        logger.debug(f\"{frame_count=}\")\n        frame_frequency = self.frame_frequency()\n        keep_frame = frame_count % frame_frequency == 0\n        logger.debug(f\"{keep_frame=}\")\n\n        if keep_frame:\n            ret, self.frame = self.capture.retrieve()\n            # self.frame = self.preprocess_frame()\n\n            # Record timestamp of frame\n            ms = MilliSecond(self.timestamp())\n\n            # Search for template in frame\n            is_match, score, match_top_left = self.match_template_scan().result\n\n            # Does this frame contain a new batter\n            new_batter = self.new_batter(frames, ms) if is_match else False\n            new_batter_name = (\n                self.batter_name(match_top_left) if new_batter else None\n            )\n\n            frame_batter_info = FrameBatterInfo(\n                ms=ms,\n                match_score=score,\n                is_batter=is_match,\n                new_batter=new_batter,\n                batter_name=new_batter_name,\n            )\n            logger.info(f\"{frame_batter_info=}\")\n            frames.append(frame_batter_info)\n\n            # Call callback if a new batter was found\n            if new_batter and self.on_batter_found:\n                self.on_batter_found(frame_batter_info)\n\n            # Call progress callback after processing each frame\n            if self.on_progress:\n                self.on_progress(frame_count, int(self.total_frames))\n\n    self.batters = BatterInfo([frame for frame in frames if frame.new_batter])\n    logger.info(f\"{self.batters=}\")\n    self.batter_count = len(self.batters)\n    logger.info(f\"{self.batter_count=}\")\n    return self\n</code></pre>"},{"location":"api/loups/#usage-examples","title":"Usage Examples","text":""},{"location":"api/loups/#basic-usage","title":"Basic Usage","text":"<pre><code>from loups import Loups\n\n# Initialize with video and template\nloups = Loups(\n    video_path=\"game_video.mp4\",\n    template_path=\"scoreboard_template.png\"\n)\n\n# Scan for chapters\nchapters = loups.scan()\n\n# Print results\nfor chapter in chapters:\n    print(f\"{chapter.timestamp} {chapter.title}\")\n</code></pre>"},{"location":"api/loups/#with-custom-options","title":"With Custom Options","text":"<pre><code>from loups import Loups\n\nloups = Loups(\n    video_path=\"video.mp4\",\n    template_path=\"template.png\",\n    threshold=0.85,              # Stricter template matching\n    ocr_confidence=0.7,          # Higher OCR confidence required\n    log_level=\"DEBUG\",           # Enable debug logging\n    log_file=\"processing.log\"   # Custom log file\n)\n\nchapters = loups.scan()\n</code></pre>"},{"location":"api/loups/#save-to-file","title":"Save to File","text":"<pre><code>from loups import Loups\n\nloups = Loups(\"video.mp4\", \"template.png\")\nchapters = loups.scan()\n\n# Save in YouTube format\nwith open(\"chapters.txt\", \"w\") as f:\n    for ch in chapters:\n        f.write(f\"{ch.timestamp} {ch.title}\\n\")\n</code></pre>"},{"location":"api/loups/#material-class-millisecond-helper-class","title":":material-class: MilliSecond Helper Class","text":""},{"location":"api/loups/#loups.loups.MilliSecond","title":"MilliSecond","text":"<p>               Bases: <code>float</code></p> <p>Custom millisecond type with YouTube chapter formatting.</p> <p>A float subclass that formats time values as YouTube-compatible chapter timestamps (MM:SS or HH:MM:SS format).</p>"},{"location":"api/loups/#loups.loups.MilliSecond-functions","title":"Functions","text":""},{"location":"api/loups/#loups.loups.MilliSecond.yt_format","title":"yt_format","text":"<pre><code>yt_format() -&gt; str\n</code></pre> <p>Format milliseconds as YouTube chapter timestamp.</p> <p>Returns:</p> Type Description <code>str</code> <p>Timestamp in MM:SS format (or HH:MM:SS if &gt;= 1 hour).</p> <p>Examples:</p> <pre><code>ms = MilliSecond(65000)  # 65 seconds\nprint(ms.yt_format())  # \"01:05\"\n\nms = MilliSecond(3665000)  # 1 hour, 1 minute, 5 seconds\nprint(ms.yt_format())  # \"01:01:05\"\n</code></pre> Source code in <code>loups/loups.py</code> <pre><code>def yt_format(self) -&gt; str:\n    \"\"\"Format milliseconds as YouTube chapter timestamp.\n\n    Returns:\n        Timestamp in MM:SS format (or HH:MM:SS if &gt;= 1 hour).\n\n    Examples:\n        ```python\n        ms = MilliSecond(65000)  # 65 seconds\n        print(ms.yt_format())  # \"01:05\"\n\n        ms = MilliSecond(3665000)  # 1 hour, 1 minute, 5 seconds\n        print(ms.yt_format())  # \"01:01:05\"\n        ```\n    \"\"\"\n    td = timedelta(milliseconds=self)\n\n    hours = td // timedelta(hours=1)\n    minutes = td // timedelta(minutes=1) % 60\n    seconds = td // timedelta(seconds=1) % 60\n\n    return (\n        f\"{minutes:02.0f}:{seconds:02.0f}\"\n        if hours == 0\n        else f\"{hours:02.0f}:{minutes:02.0f}:{seconds:02.0f}\"\n    )\n</code></pre>"},{"location":"api/loups/#millisecond-examples","title":"MilliSecond Examples","text":"<pre><code>from loups.loups import MilliSecond\n\n# Create from milliseconds\nms = MilliSecond(65000)  # 65 seconds\n\n# YouTube format\nprint(ms.yt_format())  # \"01:05\"\n\n# With hours\nms_long = MilliSecond(3665000)  # 1 hour, 1 minute, 5 seconds\nprint(ms_long.yt_format())  # \"01:01:05\"\n\n# Arithmetic\nms1 = MilliSecond(30000)\nms2 = MilliSecond(15000)\ntotal = ms1 + ms2  # 45000 milliseconds\n</code></pre>"},{"location":"api/loups/#internal-data-structures","title":"Internal Data Structures","text":""},{"location":"api/loups/#chapter-object","title":"Chapter Object","text":"<p>Each chapter returned from <code>scan()</code> typically contains:</p> <pre><code>class Chapter:\n    timestamp: str      # YouTube format \"HH:MM:SS\" or \"MM:SS\"\n    title: str          # Extracted text from frame\n    frame_number: int   # Video frame number\n    milliseconds: int   # Timestamp in milliseconds\n</code></pre>"},{"location":"api/loups/#match-results","title":"Match Results","text":"<p>Template matching results are stored internally:</p> <pre><code>loups = Loups(\"video.mp4\", \"template.png\")\nloups.scan()\n\n# Access matches\nfor frame_num, match in loups.matches.items():\n    print(f\"Frame {frame_num}:\")\n    print(f\"  Confidence: {match.confidence}\")\n    print(f\"  Location: {match.location}\")\n</code></pre>"},{"location":"api/loups/#error-handling","title":"Error Handling","text":"<pre><code>from loups import Loups\nfrom pathlib import Path\n\ntry:\n    # Check video exists\n    video_path = Path(\"video.mp4\")\n    if not video_path.exists():\n        raise FileNotFoundError(f\"Video not found: {video_path}\")\n\n    # Initialize Loups\n    loups = Loups(\n        video_path=str(video_path),\n        template_path=\"template.png\"\n    )\n\n    # Scan\n    chapters = loups.scan()\n\n    if not chapters:\n        print(\"\u26a0\ufe0f No chapters found!\")\n    else:\n        print(f\"\u2705 Found {len(chapters)} chapters\")\n\nexcept FileNotFoundError as e:\n    print(f\"\u274c Error: {e}\")\nexcept Exception as e:\n    print(f\"\u274c Unexpected error: {e}\")\n</code></pre>"},{"location":"api/loups/#performance-tips","title":"Performance Tips","text":""},{"location":"api/loups/#frame-sampling","title":"Frame Sampling","text":"<p>Control how many frames are checked:</p> <pre><code>loups = Loups(\n    video_path=\"video.mp4\",\n    template_path=\"template.png\",\n    frame_skip=5  # Check every 5th frame (faster, less accurate)\n)\n</code></pre>"},{"location":"api/loups/#template-size","title":"Template Size","text":"<p>Smaller templates = faster matching:</p> <ul> <li>Keep templates focused on the region of interest</li> <li>Avoid including large static areas</li> <li>Typical size: 200-800 pixels wide</li> </ul>"},{"location":"api/loups/#video-resolution","title":"Video Resolution","text":"<p>Lower resolution = faster processing:</p> <pre><code># Pre-process video to lower resolution\nffmpeg -i input.mp4 -vf scale=1280:-1 output.mp4\n</code></pre>"},{"location":"api/loups/#related","title":"Related","text":"<ul> <li> CLI Module - Command-line interface</li> <li> Thumbnail Extraction - Thumbnail API</li> <li> How It Works - Implementation details</li> </ul>"},{"location":"api/thumbnail/","title":"Thumbnail Extraction","text":"<p>SSIM-based thumbnail matching and extraction API.</p>"},{"location":"api/thumbnail/#module-documentation","title":"Module Documentation","text":""},{"location":"api/thumbnail/#loups.thumbnail_extractor","title":"thumbnail_extractor","text":"<p>Extract thumbnail images from video files using SSIM-based frame matching.</p>"},{"location":"api/thumbnail/#loups.thumbnail_extractor-classes","title":"Classes","text":""},{"location":"api/thumbnail/#loups.thumbnail_extractor.ThumbnailResult","title":"ThumbnailResult","text":"<p>               Bases: <code>NamedTuple</code></p> <p>Result from a thumbnail extraction operation.</p> <p>Attributes:</p> Name Type Description <code>success</code> <code>bool</code> <p>Whether thumbnail extraction succeeded.</p> <code>frame_number</code> <code>int</code> <p>Frame number where match was found.</p> <code>timestamp_ms</code> <code>float</code> <p>Timestamp of matched frame in milliseconds.</p> <code>ssim_score</code> <code>float</code> <p>SSIM similarity score of the match (0.0-1.0).</p> <code>output_path</code> <code>Path</code> <p>Path where thumbnail image was saved.</p>"},{"location":"api/thumbnail/#loups.thumbnail_extractor.ThumbnailExtractor","title":"ThumbnailExtractor","text":"<pre><code>ThumbnailExtractor(\n    video_path: Path,\n    template_path: Optional[Path] = None,\n    resolution: int = 3,\n    scan_duration: int = 120,\n    threshold: float = 0.8,\n)\n</code></pre> <p>Extract thumbnail frames from videos using SSIM-based template matching.</p> <p>Initialize ThumbnailExtractor.</p> <p>Parameters:</p> Name Type Description Default <code>video_path</code> <code>Path</code> <p>Path to video file</p> required <code>template_path</code> <code>Optional[Path]</code> <p>Path to template image (uses default if None)</p> <code>None</code> <code>resolution</code> <code>int</code> <p>Frames to check per second (matches Loups)</p> <code>3</code> <code>scan_duration</code> <code>int</code> <p>Maximum seconds to scan from video start</p> <code>120</code> <code>threshold</code> <code>float</code> <p>Minimum SSIM score to accept (0.0-1.0)</p> <code>0.8</code> Source code in <code>loups/thumbnail_extractor.py</code> <pre><code>def __init__(\n    self,\n    video_path: Path,\n    template_path: Optional[Path] = None,\n    resolution: int = 3,\n    scan_duration: int = 120,\n    threshold: float = 0.8,\n):\n    \"\"\"\n    Initialize ThumbnailExtractor.\n\n    Args:\n        video_path: Path to video file\n        template_path: Path to template image (uses default if None)\n        resolution: Frames to check per second (matches Loups)\n        scan_duration: Maximum seconds to scan from video start\n        threshold: Minimum SSIM score to accept (0.0-1.0)\n    \"\"\"\n    self.video_path = video_path\n    self.template = load_template(template_path)\n    self.resolution = resolution\n    self.scan_duration = scan_duration\n    self.threshold = threshold\n    self.capture = cv.VideoCapture(str(video_path))\n    self.frame_rate = self.capture.get(cv.CAP_PROP_FPS)\n</code></pre>"},{"location":"api/thumbnail/#loups.thumbnail_extractor.ThumbnailExtractor-functions","title":"Functions","text":"frame_frequency \u00b6 <pre><code>frame_frequency() -&gt; int\n</code></pre> <p>Calculate frame sampling interval based on resolution.</p> <p>Returns:</p> Type Description <code>int</code> <p>Number of frames to skip between samples (e.g., 10 means every 10<sup>th</sup> frame).</p> Source code in <code>loups/thumbnail_extractor.py</code> <pre><code>def frame_frequency(self) -&gt; int:\n    \"\"\"Calculate frame sampling interval based on resolution.\n\n    Returns:\n        Number of frames to skip between samples (e.g., 10 means every 10th frame).\n    \"\"\"\n    return calculate_frame_frequency(self.frame_rate, self.resolution)\n</code></pre>"},{"location":"api/thumbnail/#loups.thumbnail_extractor-functions","title":"Functions","text":""},{"location":"api/thumbnail/#loups.thumbnail_extractor.get_default_thumbnail_template","title":"get_default_thumbnail_template","text":"<pre><code>get_default_thumbnail_template() -&gt; Path\n</code></pre> <p>Get path to bundled default thumbnail template.</p> <p>Returns:</p> Type Description <code>Path</code> <p>Path to the bundled thumbnail_template.png file.</p> Source code in <code>loups/thumbnail_extractor.py</code> <pre><code>def get_default_thumbnail_template() -&gt; Path:\n    \"\"\"Get path to bundled default thumbnail template.\n\n    Returns:\n        Path to the bundled thumbnail_template.png file.\n    \"\"\"\n    return Path(__file__).parent / \"data\" / \"thumbnail_template.png\"\n</code></pre>"},{"location":"api/thumbnail/#loups.thumbnail_extractor.load_template","title":"load_template","text":"<pre><code>load_template(\n    template_path: Optional[Path] = None,\n) -&gt; ndarray\n</code></pre> <p>Load thumbnail template, using default if not specified.</p> <p>Parameters:</p> Name Type Description Default <code>template_path</code> <code>Optional[Path]</code> <p>Path to template image (None for default)</p> <code>None</code> <p>Returns:</p> Type Description <code>ndarray</code> <p>Template image as numpy array</p> <p>Raises:</p> Type Description <code>FileNotFoundError</code> <p>If template file doesn't exist</p> Source code in <code>loups/thumbnail_extractor.py</code> <pre><code>def load_template(template_path: Optional[Path] = None) -&gt; np.ndarray:\n    \"\"\"\n    Load thumbnail template, using default if not specified.\n\n    Args:\n        template_path: Path to template image (None for default)\n\n    Returns:\n        Template image as numpy array\n\n    Raises:\n        FileNotFoundError: If template file doesn't exist\n    \"\"\"\n    if template_path is None:\n        template_path = get_default_thumbnail_template()\n\n    if not template_path.exists():\n        raise FileNotFoundError(f\"Template not found: {template_path}\")\n\n    return cv.imread(str(template_path))\n</code></pre>"},{"location":"api/thumbnail/#loups.thumbnail_extractor.generate_default_output_path","title":"generate_default_output_path","text":"<pre><code>generate_default_output_path(video_path: Path) -&gt; Path\n</code></pre> <p>Generate default thumbnail output path in current working directory.</p> <p>Parameters:</p> Name Type Description Default <code>video_path</code> <code>Path</code> <p>Path to input video file</p> required <p>Returns:</p> Type Description <code>Path</code> <p>Path to output thumbnail in cwd</p> <p>Examples:</p> <p>Input: '/path/to/game.mp4' \u2192 Output: './game-thumbnail.jpg' Input: 'softball.mp4' \u2192 Output: './softball-thumbnail.jpg'</p> Source code in <code>loups/thumbnail_extractor.py</code> <pre><code>def generate_default_output_path(video_path: Path) -&gt; Path:\n    \"\"\"\n    Generate default thumbnail output path in current working directory.\n\n    Args:\n        video_path: Path to input video file\n\n    Returns:\n        Path to output thumbnail in cwd\n\n    Examples:\n        Input: '/path/to/game.mp4' \u2192 Output: './game-thumbnail.jpg'\n        Input: 'softball.mp4' \u2192 Output: './softball-thumbnail.jpg'\n    \"\"\"\n    stem = video_path.stem\n    return Path.cwd() / f\"{stem}-thumbnail.jpg\"\n</code></pre>"},{"location":"api/thumbnail/#loups.thumbnail_extractor.calculate_ssim","title":"calculate_ssim","text":"<pre><code>calculate_ssim(frame: ndarray, template: ndarray) -&gt; float\n</code></pre> <p>Calculate SSIM (Structural Similarity Index) between frame and template.</p> <p>Parameters:</p> Name Type Description Default <code>frame</code> <code>ndarray</code> <p>Video frame as numpy array</p> required <code>template</code> <code>ndarray</code> <p>Template image as numpy array</p> required <p>Returns:</p> Type Description <code>float</code> <p>SSIM score (0.0 to 1.0, where 1.0 is perfect match)</p> Source code in <code>loups/thumbnail_extractor.py</code> <pre><code>def calculate_ssim(frame: np.ndarray, template: np.ndarray) -&gt; float:\n    \"\"\"\n    Calculate SSIM (Structural Similarity Index) between frame and template.\n\n    Args:\n        frame: Video frame as numpy array\n        template: Template image as numpy array\n\n    Returns:\n        SSIM score (0.0 to 1.0, where 1.0 is perfect match)\n    \"\"\"\n    # Resize frame to match template dimensions\n    frame_resized = cv.resize(frame, (template.shape[1], template.shape[0]))\n\n    # Convert to grayscale\n    frame_gray = cv.cvtColor(frame_resized, cv.COLOR_BGR2GRAY)\n    template_gray = cv.cvtColor(template, cv.COLOR_BGR2GRAY)\n\n    # Calculate SSIM\n    score = ssim(frame_gray, template_gray)\n    return score\n</code></pre>"},{"location":"api/thumbnail/#loups.thumbnail_extractor.extract_thumbnail","title":"extract_thumbnail","text":"<pre><code>extract_thumbnail(\n    video_path: Path,\n    template_path: Optional[Path] = None,\n    output_path: Optional[Path] = None,\n    threshold: float = 0.35,\n    scan_duration: int = 120,\n    resolution: int = 3,\n    on_progress: Optional[\n        Callable[[int, int], None]\n    ] = None,\n    quiet: bool = False,\n) -&gt; Optional[ThumbnailResult]\n</code></pre> <p>Extract first frame matching template above threshold.</p> <p>Core thumbnail extraction logic used by both CLI commands. Scans video from start, checking frames at specified resolution. Stops immediately when a frame exceeds the SSIM threshold.</p> <p>Parameters:</p> Name Type Description Default <code>video_path</code> <code>Path</code> <p>Path to video file</p> required <code>template_path</code> <code>Optional[Path]</code> <p>Path to template image (uses default if None)</p> <code>None</code> <code>output_path</code> <code>Optional[Path]</code> <p>Where to save thumbnail (generates default in cwd if None)</p> <code>None</code> <code>threshold</code> <code>float</code> <p>Minimum SSIM score to accept (0.0-1.0)</p> <code>0.35</code> <code>scan_duration</code> <code>int</code> <p>Maximum seconds to scan from video start</p> <code>120</code> <code>resolution</code> <code>int</code> <p>Frames to process per second</p> <code>3</code> <code>on_progress</code> <code>Optional[Callable[[int, int], None]]</code> <p>Optional callback for progress updates</p> <code>None</code> <code>quiet</code> <code>bool</code> <p>Suppress output</p> <code>False</code> <p>Returns:</p> Type Description <code>Optional[ThumbnailResult]</code> <p>ThumbnailResult on success, None if no frame exceeds threshold</p> Source code in <code>loups/thumbnail_extractor.py</code> <pre><code>def extract_thumbnail(\n    video_path: Path,\n    template_path: Optional[Path] = None,\n    output_path: Optional[Path] = None,\n    threshold: float = 0.35,\n    scan_duration: int = 120,\n    resolution: int = 3,\n    on_progress: Optional[Callable[[int, int], None]] = None,\n    quiet: bool = False,\n) -&gt; Optional[ThumbnailResult]:\n    \"\"\"\n    Extract first frame matching template above threshold.\n\n    Core thumbnail extraction logic used by both CLI commands.\n    Scans video from start, checking frames at specified resolution.\n    Stops immediately when a frame exceeds the SSIM threshold.\n\n    Args:\n        video_path: Path to video file\n        template_path: Path to template image (uses default if None)\n        output_path: Where to save thumbnail (generates default in cwd if None)\n        threshold: Minimum SSIM score to accept (0.0-1.0)\n        scan_duration: Maximum seconds to scan from video start\n        resolution: Frames to process per second\n        on_progress: Optional callback for progress updates\n        quiet: Suppress output\n\n    Returns:\n        ThumbnailResult on success, None if no frame exceeds threshold\n    \"\"\"\n    extractor = ThumbnailExtractor(\n        video_path=video_path,\n        template_path=template_path,\n        resolution=resolution,\n        scan_duration=scan_duration,\n        threshold=threshold,\n    )\n\n    max_frames = int(scan_duration * extractor.frame_rate)\n    frame_interval = extractor.frame_frequency()\n\n    logger.debug(\n        f\"Scanning {video_path.name}: max_frames={max_frames}, \"\n        f\"frame_interval={frame_interval}, threshold={threshold}\"\n    )\n\n    frame_count = 0\n    frames_checked = 0\n\n    while frame_count &lt; max_frames:\n        ret = extractor.capture.grab()\n        if not ret:\n            break\n\n        frame_count += 1\n\n        # Sample at interval (same pattern as Loups.scan())\n        if frame_count % frame_interval != 0:\n            continue\n\n        ret, frame = extractor.capture.retrieve()\n        if not ret:\n            break\n\n        frames_checked += 1\n        score = calculate_ssim(frame, extractor.template)\n\n        logger.debug(f\"Frame {frame_count}: SSIM score = {score:.4f}\")\n\n        # Call progress callback if provided\n        if on_progress and not quiet:\n            on_progress(frame_count, max_frames)\n\n        # First frame above threshold wins!\n        if score &gt;= threshold:\n            output = output_path or generate_default_output_path(video_path)\n            cv.imwrite(str(output), frame)\n            timestamp = extractor.capture.get(cv.CAP_PROP_POS_MSEC)\n\n            logger.info(\n                f\"Thumbnail extracted: frame={frame_count}, \"\n                f\"timestamp={timestamp:.0f}ms, score={score:.4f}, path={output}\"\n            )\n\n            return ThumbnailResult(\n                success=True,\n                frame_number=frame_count,\n                timestamp_ms=timestamp,\n                ssim_score=score,\n                output_path=output,\n            )\n\n    # No match found - log warning and return None\n    logger.warning(\n        f\"No frame exceeded threshold {threshold} \"\n        f\"within {scan_duration}s (checked {frames_checked} frames)\"\n    )\n    return None\n</code></pre>"},{"location":"api/thumbnail/#material-flow-chart-extraction-process","title":":material-flow-chart: Extraction Process","text":"<pre><code>graph TD\n    A[Start: Video + Template] --&gt; B{Load Template}\n    B --&gt; C[Initialize VideoCapture]\n    C --&gt; D{Scan Frames}\n\n    D --&gt; E[Read Next Frame]\n    E --&gt; F{Frame Valid?}\n\n    F --&gt;|No| G[End: No Match Found]\n    F --&gt;|Yes| H[Resize to Template Size]\n\n    H --&gt; I[Calculate SSIM Score]\n    I --&gt; J{Score &gt;= Threshold?}\n\n    J --&gt;|No| K{More Frames?}\n    K --&gt;|Yes, within duration| E\n    K --&gt;|No, exceeded duration| G\n\n    J --&gt;|Yes| L[Match Found!]\n    L --&gt; M[Save as JPEG]\n    M --&gt; N[End: Success]\n\n    style A fill:#00ffff,stroke:#000,color:#000\n    style L fill:#66bb6a,stroke:#000,color:#000\n    style N fill:#00ffff,stroke:#000,color:#000\n    style G fill:#ef5350,stroke:#000,color:#fff\n    style I fill:#00b8d4,stroke:#000,color:#fff</code></pre> <p>Key Steps:</p> <ol> <li>Template Loading - Load and validate template image</li> <li>Frame Scanning - Iterate through video frames at specified FPS</li> <li>SSIM Calculation - Compute Structural Similarity Index</li> <li>Threshold Check - Compare against minimum threshold</li> <li>First-Match Strategy - Stop immediately on first match</li> <li>Save Output - Write matched frame as JPEG</li> </ol>"},{"location":"api/thumbnail/#usage-examples","title":"Usage Examples","text":""},{"location":"api/thumbnail/#basic-extraction","title":"Basic Extraction","text":"<pre><code>from loups.thumbnail_extractor import extract_thumbnail\n\n# Extract with default template\nthumbnail_path = extract_thumbnail(\n    video_path=\"game_video.mp4\"\n)\n\nprint(f\"Thumbnail saved to: {thumbnail_path}\")\n</code></pre>"},{"location":"api/thumbnail/#custom-template","title":"Custom Template","text":"<pre><code>from loups.thumbnail_extractor import extract_thumbnail\n\nthumbnail_path = extract_thumbnail(\n    video_path=\"video.mp4\",\n    template_path=\"title_screen_template.png\",\n    output_path=\"custom_thumbnail.jpg\"\n)\n</code></pre>"},{"location":"api/thumbnail/#fine-tuned-extraction","title":"Fine-Tuned Extraction","text":"<pre><code>from loups.thumbnail_extractor import extract_thumbnail\n\nthumbnail_path = extract_thumbnail(\n    video_path=\"video.mp4\",\n    template_path=\"template.png\",\n    output_path=\"thumb.jpg\",\n    threshold=0.7,           # Stricter matching (default: 0.35)\n    scan_duration=180,       # Scan first 3 minutes (default: 120)\n    frames_per_second=5,     # Sample 5 FPS (default: 3)\n    quiet=False              # Show progress\n)\n</code></pre>"},{"location":"api/thumbnail/#parameters-explained","title":"Parameters Explained","text":""},{"location":"api/thumbnail/#threshold-00-10","title":"Threshold (0.0 - 1.0)","text":"<p>The SSIM threshold determines how similar a frame must be to the template:</p> Threshold Matching Behavior Use Case <code>0.2 - 0.4</code> Loose - More matches Varied title screens <code>0.5 - 0.7</code> Balanced - Moderate Most use cases <code>0.8 - 1.0</code> Strict - Exact match Identical frames only <p>Default: <code>0.35</code> (loose, good for varied content)</p> <p>Finding the Right Threshold</p> <p>Start with default (0.35) and adjust:</p> <ul> <li>Too many false positives? \u2192 Increase threshold</li> <li>Can't find match? \u2192 Decrease threshold</li> <li>Test on sample to find sweet spot</li> </ul>"},{"location":"api/thumbnail/#scan-duration","title":"Scan Duration","text":"<p>How many seconds to scan from the beginning:</p> <pre><code># Scan first 2 minutes\nextract_thumbnail(video_path=\"video.mp4\", scan_duration=120)\n\n# Scan first 5 minutes\nextract_thumbnail(video_path=\"video.mp4\", scan_duration=300)\n\n# Scan entire video (slow!)\nextract_thumbnail(video_path=\"video.mp4\", scan_duration=999999)\n</code></pre> <p>Performance Impact</p> <p>Longer scan duration = slower extraction. Most title screens appear in first 2 minutes.</p>"},{"location":"api/thumbnail/#frames-per-second","title":"Frames Per Second","text":"<p>Frame sampling rate:</p> <pre><code># Sample every frame (slow, thorough)\nextract_thumbnail(video_path=\"video.mp4\", frames_per_second=30)\n\n# Sample 3 FPS (default, balanced)\nextract_thumbnail(video_path=\"video.mp4\", frames_per_second=3)\n\n# Sample 1 FPS (fast, might miss frame)\nextract_thumbnail(video_path=\"video.mp4\", frames_per_second=1)\n</code></pre> <p>Trade-off: Higher FPS = more accurate but slower</p>"},{"location":"api/thumbnail/#ssim-vs-template-matching","title":"SSIM vs Template Matching","text":"<p>Loups uses SSIM (Structural Similarity Index) for thumbnails instead of template matching:</p> Feature Template Matching SSIM Purpose Find specific regions Compare full frames Speed  Fast  Moderate Accuracy  High for patterns  High for images Use Case Chapter detection Thumbnail extraction Sensitivity Position-sensitive Content-aware <p>Why SSIM for thumbnails?</p> <ul> <li> Accounts for overall visual similarity</li> <li> Robust to minor variations</li> <li> Good for comparing full frames</li> <li> Perceptually meaningful</li> </ul>"},{"location":"api/thumbnail/#testing-debugging","title":"Testing &amp; Debugging","text":""},{"location":"api/thumbnail/#verify-template-quality","title":"Verify Template Quality","text":"<pre><code>import cv2\nfrom skimage.metrics import structural_similarity as ssim\n\n# Load template and test frame\ntemplate = cv2.imread(\"template.png\")\ntest_frame = cv2.imread(\"test_frame.png\")\n\n# Resize to same size\ntest_frame_resized = cv2.resize(\n    test_frame,\n    (template.shape[1], template.shape[0])\n)\n\n# Calculate SSIM\nscore = ssim(template, test_frame_resized, multichannel=True)\nprint(f\"SSIM Score: {score:.3f}\")\n\n# Interpretation\nif score &gt;= 0.7:\n    print(\"\u2705 Strong match\")\nelif score &gt;= 0.4:\n    print(\"\u26a0\ufe0f Moderate match\")\nelse:\n    print(\"\u274c Poor match\")\n</code></pre>"},{"location":"api/thumbnail/#extract-multiple-frames","title":"Extract Multiple Frames","text":"<p>For testing, you might want to extract multiple frames:</p> <pre><code>import cv2\nfrom pathlib import Path\n\ndef extract_frames(video_path, output_dir, fps=1, duration=120):\n    \"\"\"Extract frames for template testing.\"\"\"\n    output_dir = Path(output_dir)\n    output_dir.mkdir(exist_ok=True)\n\n    cap = cv2.VideoCapture(video_path)\n    video_fps = cap.get(cv2.CAP_PROP_FPS)\n    frame_interval = int(video_fps / fps)\n\n    frame_count = 0\n    saved_count = 0\n\n    while frame_count &lt; (duration * video_fps):\n        ret, frame = cap.read()\n        if not ret:\n            break\n\n        if frame_count % frame_interval == 0:\n            output_path = output_dir / f\"frame_{saved_count:04d}.jpg\"\n            cv2.imwrite(str(output_path), frame)\n            saved_count += 1\n\n        frame_count += 1\n\n    cap.release()\n    print(f\"Extracted {saved_count} frames to {output_dir}\")\n\n# Usage\nextract_frames(\"video.mp4\", \"test_frames\", fps=1, duration=60)\n</code></pre>"},{"location":"api/thumbnail/#batch-thumbnail-extraction","title":"Batch Thumbnail Extraction","text":""},{"location":"api/thumbnail/#process-multiple-videos","title":"Process Multiple Videos","text":"<pre><code>from pathlib import Path\nfrom loups.thumbnail_extractor import extract_thumbnail\n\nvideo_dir = Path(\"videos\")\nthumb_dir = Path(\"thumbnails\")\nthumb_dir.mkdir(exist_ok=True)\n\nfor video in video_dir.glob(\"*.mp4\"):\n    print(f\"Extracting thumbnail for: {video.name}\")\n\n    try:\n        thumbnail = extract_thumbnail(\n            video_path=str(video),\n            output_path=str(thumb_dir / f\"{video.stem}.jpg\"),\n            quiet=True\n        )\n        print(f\"  \u2705 Saved: {thumbnail}\")\n    except Exception as e:\n        print(f\"  \u274c Error: {e}\")\n</code></pre>"},{"location":"api/thumbnail/#parallel-processing","title":"Parallel Processing","text":"<pre><code>from concurrent.futures import ThreadPoolExecutor\nfrom pathlib import Path\nfrom loups.thumbnail_extractor import extract_thumbnail\n\ndef extract_single(video_path):\n    \"\"\"Extract thumbnail for single video.\"\"\"\n    try:\n        output = f\"thumbnails/{video_path.stem}.jpg\"\n        return extract_thumbnail(\n            video_path=str(video_path),\n            output_path=output,\n            quiet=True\n        )\n    except Exception as e:\n        return f\"Error: {e}\"\n\n# Get all videos\nvideos = list(Path(\"videos\").glob(\"*.mp4\"))\n\n# Process in parallel\nwith ThreadPoolExecutor(max_workers=4) as executor:\n    results = executor.map(extract_single, videos)\n\n# Print results\nfor video, result in zip(videos, results):\n    print(f\"{video.name}: {result}\")\n</code></pre>"},{"location":"api/thumbnail/#tips-best-practices","title":"Tips &amp; Best Practices","text":"<p>Best Practices</p> <ul> <li> Template from actual frame - Use a real frame from your video</li> <li> Start with defaults - Adjust only if needed</li> <li> Test on one video first - Verify settings work</li> <li> Use quiet mode in scripts - Cleaner output</li> </ul> <p>Common Issues</p> <p>No match found?</p> <ul> <li>Try lower threshold (0.2 - 0.3)</li> <li>Increase scan duration</li> <li>Increase frames_per_second</li> <li>Verify template matches video content</li> </ul> <p>Wrong frame matched?</p> <ul> <li>Increase threshold for stricter matching</li> <li>Use more specific template</li> <li>Reduce scan duration if title appears early</li> </ul>"},{"location":"api/thumbnail/#related","title":"Related","text":"<ul> <li> Loups Class - Main API</li> <li> CLI Module - Command-line usage</li> <li> CLI Thumbnail Reference - User guide</li> </ul>"},{"location":"developer/","title":"Developer Guide","text":"<p>Technical documentation for contributors and developers working with Loups.</p>"},{"location":"developer/#developer-documentation","title":"Developer Documentation","text":""},{"location":"developer/#architecture","title":"Architecture","text":"<p>System design and module structure</p>"},{"location":"developer/#how-it-works","title":"How It Works","text":"<p>Detailed technical implementation</p>"},{"location":"developer/#contributing","title":"Contributing","text":"<p>Contribution guidelines and workflow</p>"},{"location":"developer/#quick-start-for-developers","title":"Quick Start for Developers","text":""},{"location":"developer/#development-setup","title":"Development Setup","text":"<pre><code># Clone repository\ngit clone https://github.com/jcspeegs/loups.git\ncd loups\n\n# Using devenv (recommended)\ndevenv shell\n\n# Or using uv\nuv venv\nsource .venv/bin/activate  # or .venv\\Scripts\\activate on Windows\nuv pip install -e \".[dev]\"\n\n# Run tests\nuv run python -m pytest\n\n# Run linting\nflake8 loups tests\nblack --check loups tests\n</code></pre>"},{"location":"developer/#project-structure","title":"Project Structure","text":"<pre><code>loups/\n\u251c\u2500\u2500 loups/                  # Main package\n\u2502   \u251c\u2500\u2500 __init__.py\n\u2502   \u251c\u2500\u2500 loups.py           # Core Loups class\n\u2502   \u251c\u2500\u2500 cli.py             # CLI interface\n\u2502   \u251c\u2500\u2500 match_template_scan.py\n\u2502   \u251c\u2500\u2500 thumbnail_extractor.py\n\u2502   \u251c\u2500\u2500 frame_utils.py\n\u2502   \u2514\u2500\u2500 geometry.py\n\u251c\u2500\u2500 tests/                  # Test suite\n\u251c\u2500\u2500 docs/                   # Documentation\n\u251c\u2500\u2500 devenv.nix             # Development environment\n\u251c\u2500\u2500 pyproject.toml         # Project configuration\n\u2514\u2500\u2500 README.md\n</code></pre>"},{"location":"developer/#development-tools","title":"Development Tools","text":""},{"location":"developer/#code-quality","title":"Code Quality","text":"<p>Loups uses comprehensive linting and formatting:</p> Tool Purpose Config black Code formatting pyproject.toml flake8 Base style checking (PEP 8) .flake8 flake8-bugbear Additional bug and design problems .flake8 flake8-docstrings Docstring validation (PEP 257, D401 imperative mood) .flake8 pep8-naming PEP 8 naming conventions .flake8 flake8-quotes Quote style consistency .flake8 mccabe Cyclomatic complexity checker .flake8 isort Import sorting pyproject.toml pytest Testing pytest.ini"},{"location":"developer/#pre-commit-hooks","title":"Pre-commit Hooks","text":"<p>Pre-commit hooks ensure code quality:</p> <pre><code># Hooks run automatically on commit\ngit commit -m \"Your message\"\n\n# Manual run\ndevenv shell\npre-commit run --all-files\n</code></pre> <p>Active hooks: -  black (formatting) -  flake8 (linting) -  isort (imports) -  pytest (tests)</p>"},{"location":"developer/#testing","title":"Testing","text":""},{"location":"developer/#run-tests","title":"Run Tests","text":"<pre><code># All tests\nuv run python -m pytest\n\n# With coverage\nuv run python -m pytest --cov=loups --cov-report=html\n\n# Specific test file\nuv run python -m pytest tests/test_loups.py\n\n# Specific test\nuv run python -m pytest tests/test_loups.py::test_function_name\n\n# Verbose output\nuv run python -m pytest -v\n</code></pre>"},{"location":"developer/#writing-tests","title":"Writing Tests","text":"<p>Follow existing patterns:</p> <pre><code>import pytest\nfrom loups import Loups\n\ndef test_loups_initialization():\n    \"\"\"Test Loups class initialization.\"\"\"\n    loups = Loups(\n        video_path=\"test_video.mp4\",\n        template_path=\"test_template.png\"\n    )\n\n    assert loups.video_path == \"test_video.mp4\"\n    assert loups.template_path == \"test_template.png\"\n\ndef test_chapter_generation():\n    \"\"\"Test chapter generation from video.\"\"\"\n    loups = Loups(\"test_video.mp4\", \"template.png\")\n    chapters = loups.scan()\n\n    assert len(chapters) &gt; 0\n    assert all(hasattr(ch, 'timestamp') for ch in chapters)\n    assert all(hasattr(ch, 'title') for ch in chapters)\n</code></pre>"},{"location":"developer/#documentation","title":"Documentation","text":""},{"location":"developer/#build-documentation","title":"Build Documentation","text":"<pre><code># Serve locally\ndevenv shell\ndocs  # or: mkdocs serve\n\n# Open browser\nopen http://127.0.0.1:8000\n\n# Build static site\nmkdocs build\n</code></pre>"},{"location":"developer/#docstring-style","title":"Docstring Style","text":"<p>Use Google-style docstrings with imperative mood:</p> <pre><code>def process_frame(frame, template):\n    \"\"\"Process video frame with template matching.\n\n    Args:\n        frame: Video frame as numpy array.\n        template: Template image for matching.\n\n    Returns:\n        Match confidence score (0.0 to 1.0).\n\n    Raises:\n        ValueError: If frame or template is invalid.\n\n    Examples:\n        ```python\n        score = process_frame(frame, template)\n        if score &gt; 0.8:\n            print(\"Strong match!\")\n        ```\n    \"\"\"\n    # Implementation\n    pass\n</code></pre> <p>D401 Compliance</p> <p>Docstrings must start with imperative verb:</p> <ul> <li> \"Process video frame\" (correct)</li> <li> \"Processes video frame\" (incorrect)</li> </ul>"},{"location":"developer/#git-workflow","title":"Git Workflow","text":""},{"location":"developer/#branch-strategy","title":"Branch Strategy","text":"<pre><code># Create feature branch from main\ngit checkout main\ngit pull origin main\ngit checkout -b feature/your-feature-name\n\n# Make changes\ngit add .\ngit commit -m \"Add feature description\"\n\n# Push to GitHub\ngit push origin feature/your-feature-name\n\n# Open pull request on GitHub\n</code></pre>"},{"location":"developer/#commit-messages","title":"Commit Messages","text":"<p>Follow conventional commits:</p> <pre><code># Format\ntype(scope): description\n\n# Examples\nfeat(cli): add batch processing command\nfix(ocr): improve text extraction accuracy\ndocs(api): update Loups class documentation\ntest(thumbnail): add SSIM threshold tests\nrefactor(core): simplify frame processing logic\n</code></pre>"},{"location":"developer/#additional-resources","title":"Additional Resources","text":"<ul> <li> Architecture Overview - System design</li> <li> How It Works - Implementation details</li> <li> Contributing Guide - Contribution workflow</li> <li> API Reference - API documentation</li> </ul>"},{"location":"developer/#developer-faqs","title":"Developer FAQs","text":"How do I add a new feature? <ol> <li>Create issue on GitHub describing the feature</li> <li>Fork and create feature branch</li> <li>Implement with tests and docs</li> <li>Submit pull request</li> <li>See Contributing Guide</li> </ol> How are dependencies managed? <ul> <li>Runtime deps: pyproject.toml <code>dependencies</code></li> <li>Dev deps: devenv.nix for development environment</li> <li>CI/CD: GitHub Actions with Nix</li> </ul> What Python versions are supported? <p>Python 3.13+ only. Uses modern Python features.</p> How do I debug video processing? <pre><code>loups = Loups(\n    video_path=\"video.mp4\",\n    template_path=\"template.png\",\n    log_level=\"DEBUG\",\n    log_file=\"debug.log\"\n)\n\n# Check debug.log for detailed processing info\n</code></pre>"},{"location":"developer/architecture/","title":"Architecture","text":"<p>System architecture and module design of Loups.</p>"},{"location":"developer/architecture/#system-overview","title":"System Overview","text":"<p>Loups is built as a modular Python application with clear separation of concerns:</p> <pre><code>graph TB\n    subgraph \"User Interface Layer\"\n        CLI[CLI Module&lt;br/&gt;loups.cli]\n        API[Python API&lt;br/&gt;loups.Loups]\n    end\n\n    subgraph \"Core Processing Layer\"\n        CORE[Core Engine&lt;br/&gt;loups.loups.Loups]\n        SCAN[Template Scanner&lt;br/&gt;match_template_scan]\n        OCR[OCR Engine&lt;br/&gt;EasyOCR]\n        THUMB[Thumbnail Extractor&lt;br/&gt;thumbnail_extractor]\n    end\n\n    subgraph \"Utility Layer\"\n        FRAME[Frame Utils&lt;br/&gt;frame_utils]\n        GEOM[Geometry&lt;br/&gt;geometry]\n        TIME[Time Utils&lt;br/&gt;MilliSecond]\n    end\n\n    subgraph \"External Dependencies\"\n        CV[OpenCV&lt;br/&gt;Video I/O]\n        EOCR[EasyOCR&lt;br/&gt;Text Recognition]\n        SSIM[scikit-image&lt;br/&gt;SSIM Matching]\n    end\n\n    CLI --&gt; CORE\n    API --&gt; CORE\n\n    CORE --&gt; SCAN\n    CORE --&gt; OCR\n    CORE --&gt; THUMB\n    CORE --&gt; TIME\n\n    SCAN --&gt; FRAME\n    SCAN --&gt; GEOM\n    THUMB --&gt; FRAME\n\n    FRAME --&gt; CV\n    SCAN --&gt; CV\n    OCR --&gt; EOCR\n    THUMB --&gt; SSIM\n\n    style CLI fill:#00ffff,stroke:#000,color:#000\n    style API fill:#00ffff,stroke:#000,color:#000\n    style CORE fill:#00b8d4,stroke:#000,color:#fff\n    style SCAN fill:#00b8d4,stroke:#000,color:#fff\n    style OCR fill:#00b8d4,stroke:#000,color:#fff\n    style THUMB fill:#00b8d4,stroke:#000,color:#fff</code></pre>"},{"location":"developer/architecture/#module-breakdown","title":"Module Breakdown","text":""},{"location":"developer/architecture/#user-interface-layer","title":"User Interface Layer","text":""},{"location":"developer/architecture/#cli-module-loupscli","title":"CLI Module (<code>loups.cli</code>)","text":"<p>Purpose: Command-line interface using Typer and Rich</p> <p>Responsibilities: -  Parse command-line arguments -  Display rich progress bars and output -  Handle user interactions -  Route to main command or thumbnail subcommand</p> <p>Key Components: - <code>app</code>: Typer application instance - <code>main()</code>: Main chapter scanning command - <code>thumbnail_command()</code>: Thumbnail extraction subcommand</p> <p>Dependencies: - Typer (CLI framework) - Rich (terminal formatting) - Core Loups engine</p>"},{"location":"developer/architecture/#python-api-loupsloups","title":"Python API (<code>loups.Loups</code>)","text":"<p>Purpose: Programmatic interface for Python developers</p> <p>Responsibilities: -  Provide clean Python API -  Manage video processing workflow -  Return structured chapter data</p>"},{"location":"developer/architecture/#core-processing-layer","title":"Core Processing Layer","text":""},{"location":"developer/architecture/#core-engine-loupsloupsloups","title":"Core Engine (<code>loups.loups.Loups</code>)","text":"<p>Purpose: Main orchestration class</p> <p>Responsibilities: -  Initialize video capture -  Coordinate template matching -  Manage OCR extraction -  Generate chapter timestamps -  Handle logging and error management</p> <p>Key Methods: <pre><code>class Loups:\n    def __init__(video_path, template_path, **kwargs)\n    def scan() -&gt; List[Chapter]\n    def _process_frame(frame_num, frame) -&gt; Optional[Match]\n    def _extract_text(frame, match_region) -&gt; str\n</code></pre></p> <p>Data Flow: 1. Load video and template 2. Scan frames for template matches 3. Extract text from matched regions via OCR 4. Generate timestamped chapters 5. Return structured results</p>"},{"location":"developer/architecture/#template-scanner-match_template_scan","title":"Template Scanner (<code>match_template_scan</code>)","text":"<p>Purpose: OpenCV template matching logic</p> <p>Responsibilities: -  Perform template matching on video frames -  Calculate match confidence scores -  Identify match regions (bounding boxes) -  Filter matches by confidence threshold</p> <p>Algorithm: <pre><code>def match_template(frame, template, threshold=0.8):\n    \"\"\"Match template against frame using cv2.matchTemplate.\"\"\"\n    # Normalize frame and template\n    # Perform template matching (TM_CCOEFF_NORMED)\n    # Find matches above threshold\n    # Return match locations and confidence\n</code></pre></p>"},{"location":"developer/architecture/#ocr-engine-easyocr-integration","title":"OCR Engine (EasyOCR Integration)","text":"<p>Purpose: Text extraction from matched frames</p> <p>Responsibilities: -  Initialize EasyOCR reader -  Extract text from frame regions -  Apply confidence filtering -  Sort text left-to-right -  Combine into chapter titles</p> <p>Configuration: - Languages: English (default) - Confidence threshold: 0.6 (configurable) - GPU acceleration: Auto-detected</p>"},{"location":"developer/architecture/#thumbnail-extractor-thumbnail_extractor","title":"Thumbnail Extractor (<code>thumbnail_extractor</code>)","text":"<p>Purpose: SSIM-based thumbnail extraction</p> <p>Responsibilities: -  Load thumbnail template -  Scan video frames with SSIM matching -  Find first match above threshold -  Save matched frame as JPEG</p> <p>Algorithm: <pre><code>def extract_thumbnail(video_path, template_path, threshold=0.35):\n    \"\"\"Extract thumbnail using SSIM scoring.\"\"\"\n    # Load template\n    # Iterate frames (limited by scan_duration)\n    # Calculate SSIM for each frame\n    # Return first frame above threshold\n    # Save as JPEG\n</code></pre></p>"},{"location":"developer/architecture/#utility-layer","title":"Utility Layer","text":""},{"location":"developer/architecture/#frame-utils-frame_utils","title":"Frame Utils (<code>frame_utils</code>)","text":"<p>Purpose: Video frame manipulation utilities</p> <p>Functions: - <code>extract_frame(video_path, frame_num)</code> - Get specific frame - <code>get_video_fps(video_path)</code> - Get video frame rate - <code>get_video_duration(video_path)</code> - Get video length - <code>resize_frame(frame, width, height)</code> - Resize operations</p>"},{"location":"developer/architecture/#geometry-geometry","title":"Geometry (<code>geometry</code>)","text":"<p>Purpose: Bounding box and region calculations</p> <p>Functions: - <code>calculate_region(match_loc, template_size)</code> - Compute match region - <code>crop_region(frame, region)</code> - Extract frame region - <code>merge_overlapping_regions(regions)</code> - Combine close matches</p>"},{"location":"developer/architecture/#time-utils-millisecond","title":"Time Utils (<code>MilliSecond</code>)","text":"<p>Purpose: Timestamp formatting</p> <p>Class: <pre><code>class MilliSecond:\n    \"\"\"Convert milliseconds to YouTube timestamp format.\"\"\"\n\n    def __init__(ms: int)\n    def yt_format() -&gt; str  # Returns \"HH:MM:SS\" or \"MM:SS\"\n</code></pre></p>"},{"location":"developer/architecture/#data-flow","title":"Data Flow","text":""},{"location":"developer/architecture/#chapter-scanning-flow","title":"Chapter Scanning Flow","text":"<pre><code>graph LR\n    A[Video File] --&gt; B[Load Video]\n    C[Template File] --&gt; D[Load Template]\n\n    B --&gt; E[Frame Iterator]\n    D --&gt; E\n\n    E --&gt; F{For Each Frame}\n    F --&gt; G[Template Match]\n\n    G --&gt; H{Match Found?}\n    H --&gt;|No| F\n    H --&gt;|Yes| I[Extract Region]\n\n    I --&gt; J[Run OCR]\n    J --&gt; K[Parse Text]\n    K --&gt; L[Create Chapter]\n\n    L --&gt; M{More Frames?}\n    M --&gt;|Yes| F\n    M --&gt;|No| N[Return Chapters]\n\n    style A fill:#00ffff,stroke:#000,color:#000\n    style C fill:#00ffff,stroke:#000,color:#000\n    style N fill:#00ffff,stroke:#000,color:#000\n    style G fill:#00b8d4,stroke:#000,color:#fff\n    style J fill:#00b8d4,stroke:#000,color:#fff</code></pre>"},{"location":"developer/architecture/#thumbnail-extraction-flow","title":"Thumbnail Extraction Flow","text":"<pre><code>graph LR\n    A[Video File] --&gt; B[Load Video]\n    C[Thumbnail Template] --&gt; D[Load Template]\n\n    B --&gt; E[Frame Sampler&lt;br/&gt;scan_duration, fps]\n    D --&gt; E\n\n    E --&gt; F{Sample Frame}\n    F --&gt; G[Resize to Template Size]\n\n    G --&gt; H[Calculate SSIM]\n    H --&gt; I{Score &gt;= Threshold?}\n\n    I --&gt;|No| J{More Frames?}\n    J --&gt;|Yes| F\n    J --&gt;|No| K[No Match Found]\n\n    I --&gt;|Yes| L[Match Found]\n    L --&gt; M[Save JPEG]\n\n    style A fill:#00ffff,stroke:#000,color:#000\n    style C fill:#00ffff,stroke:#000,color:#000\n    style M fill:#66bb6a,stroke:#000,color:#000\n    style K fill:#ef5350,stroke:#000,color:#fff\n    style H fill:#00b8d4,stroke:#000,color:#fff</code></pre>"},{"location":"developer/architecture/#external-dependencies","title":"External Dependencies","text":""},{"location":"developer/architecture/#opencv-opencv-python-headless","title":"OpenCV (<code>opencv-python-headless</code>)","text":"<p>Usage: - Video capture and frame extraction - Template matching (cv2.matchTemplate) - Image operations (resize, crop, color conversion)</p> <p>Why headless? - Smaller package size - No GUI dependencies needed - Perfect for server/CLI use</p>"},{"location":"developer/architecture/#easyocr","title":"EasyOCR","text":"<p>Usage: - Optical Character Recognition - Text detection and extraction - Confidence scoring</p> <p>Features Used: - Multi-language support (English by default) - GPU acceleration when available - Bounding box detection - Confidence scores</p>"},{"location":"developer/architecture/#scikit-image","title":"scikit-image","text":"<p>Usage: - SSIM (Structural Similarity Index) calculation - Image comparison for thumbnail matching</p> <p>Why SSIM? - Perceptually meaningful similarity metric - Robust to minor variations - Better than pixel-by-pixel comparison</p>"},{"location":"developer/architecture/#rich","title":"Rich","text":"<p>Usage: - Beautiful terminal progress bars - Colored console output - Table formatting - Error display</p>"},{"location":"developer/architecture/#typer","title":"Typer","text":"<p>Usage: - CLI framework - Argument parsing - Subcommand routing - Help generation</p>"},{"location":"developer/architecture/#configuration-settings","title":"Configuration &amp; Settings","text":""},{"location":"developer/architecture/#environment-variables","title":"Environment Variables","text":"<pre><code># Debug mode\nLOUPS_DEBUG=1\n\n# Custom OCR languages\nLOUPS_OCR_LANG=en,es\n\n# GPU usage\nLOUPS_USE_GPU=0  # Disable GPU\n</code></pre>"},{"location":"developer/architecture/#config-file-support-future","title":"Config File Support (Future)","text":"<pre><code># loups.yaml (planned)\ndefaults:\n  threshold: 0.8\n  ocr_confidence: 0.6\n  log_level: INFO\n\ntemplates:\n  softball: path/to/softball_template.png\n  podcast: path/to/podcast_template.png\n</code></pre>"},{"location":"developer/architecture/#design-patterns","title":"Design Patterns","text":""},{"location":"developer/architecture/#separation-of-concerns","title":"Separation of Concerns","text":"<p>Each module has a single, well-defined responsibility:</p> <ul> <li>CLI - User interaction only</li> <li>Core - Business logic orchestration</li> <li>Utils - Reusable helper functions</li> <li>Dependencies - External library wrappers</li> </ul>"},{"location":"developer/architecture/#dependency-injection","title":"Dependency Injection","text":"<pre><code>class Loups:\n    def __init__(\n        self,\n        video_path: str,\n        template_path: str,\n        ocr_engine: Optional[OCREngine] = None,  # Injectable\n        video_reader: Optional[VideoReader] = None  # Injectable\n    ):\n        self.ocr_engine = ocr_engine or DefaultOCREngine()\n        self.video_reader = video_reader or OpenCVReader(video_path)\n</code></pre>"},{"location":"developer/architecture/#error-handling","title":"Error Handling","text":"<p>Consistent error handling throughout:</p> <pre><code>try:\n    loups = Loups(video_path, template_path)\n    chapters = loups.scan()\nexcept FileNotFoundError as e:\n    logger.error(f\"File not found: {e}\")\n    raise\nexcept OCRError as e:\n    logger.error(f\"OCR failed: {e}\")\n    raise\nexcept Exception as e:\n    logger.error(f\"Unexpected error: {e}\")\n    raise\n</code></pre>"},{"location":"developer/architecture/#testing-architecture","title":"Testing Architecture","text":""},{"location":"developer/architecture/#test-structure","title":"Test Structure","text":"<pre><code>tests/\n\u251c\u2500\u2500 test_loups.py              # Core Loups class\n\u251c\u2500\u2500 test_cli.py                # CLI commands\n\u251c\u2500\u2500 test_thumbnail.py          # Thumbnail extraction\n\u251c\u2500\u2500 test_match_template.py     # Template matching\n\u251c\u2500\u2500 test_frame_utils.py        # Frame utilities\n\u251c\u2500\u2500 fixtures/                  # Test data\n\u2502   \u251c\u2500\u2500 test_video.mp4\n\u2502   \u251c\u2500\u2500 test_template.png\n\u2502   \u2514\u2500\u2500 expected_output.txt\n\u2514\u2500\u2500 conftest.py                # Pytest configuration\n</code></pre>"},{"location":"developer/architecture/#test-categories","title":"Test Categories","text":"Type Coverage Tools Unit Tests Individual functions pytest Integration Tests Module interactions pytest E2E Tests Full workflow pytest + fixtures CLI Tests Command execution Typer CliRunner"},{"location":"developer/architecture/#related-documentation","title":"Related Documentation","text":"<ul> <li> How It Works - Detailed implementation</li> <li> Contributing - Contribution guide</li> <li> API Reference - API documentation</li> </ul>"},{"location":"developer/contributing/","title":"Contributing","text":"<p>Welcome contributors! This guide will help you get started with contributing to Loups.</p>"},{"location":"developer/contributing/#ways-to-contribute","title":"Ways to Contribute","text":""},{"location":"developer/contributing/#bug-reports","title":"Bug Reports","text":"<p>Found a bug? Open an issue with details and reproduction steps</p>"},{"location":"developer/contributing/#feature-requests","title":"Feature Requests","text":"<p>Have an idea? Suggest new features or improvements</p>"},{"location":"developer/contributing/#code-contributions","title":"Code Contributions","text":"<p>Submit pull requests with bug fixes or new features</p>"},{"location":"developer/contributing/#documentation","title":"Documentation","text":"<p>Help improve docs, add examples, fix typos</p>"},{"location":"developer/contributing/#templates-examples","title":"Templates &amp; Examples","text":"<p>Share custom templates and interesting use cases</p>"},{"location":"developer/contributing/#community-support","title":"Community Support","text":"<p>Help others in issues and discussions</p>"},{"location":"developer/contributing/#getting-started","title":"Getting Started","text":""},{"location":"developer/contributing/#1-fork-clone","title":"1. Fork &amp; Clone","text":"<pre><code># Fork on GitHub\n# (Click \"Fork\" button on https://github.com/jcspeegs/loups)\n\n# Clone your fork\ngit clone https://github.com/YOUR_USERNAME/loups.git\ncd loups\n\n# Add upstream remote\ngit remote add upstream https://github.com/jcspeegs/loups.git\n</code></pre>"},{"location":"developer/contributing/#2-set-up-development-environment","title":"2. Set Up Development Environment","text":"devenv (Recommended) uv pip <pre><code># Enter development shell\ndevenv shell\n\n# Verify setup\npython --version  # Should be 3.13+\npytest --version\n</code></pre> <pre><code># Create virtual environment\nuv venv\nsource .venv/bin/activate  # or .venv\\Scripts\\activate on Windows\n\n# Install in development mode\nuv pip install -e \".[dev]\"\n\n# Verify\nloups --help\npytest --version\n</code></pre> <pre><code># Create virtual environment\npython -m venv .venv\nsource .venv/bin/activate  # or .venv\\Scripts\\activate on Windows\n\n# Install in development mode\npip install -e \".[dev]\"\n</code></pre>"},{"location":"developer/contributing/#3-create-a-branch","title":"3. Create a Branch","text":"<pre><code># Update main\ngit checkout main\ngit pull upstream main\n\n# Create feature branch\ngit checkout -b feature/your-feature-name\n\n# Or for bug fixes\ngit checkout -b fix/issue-description\n</code></pre>"},{"location":"developer/contributing/#development-workflow","title":"Development Workflow","text":""},{"location":"developer/contributing/#making-changes","title":"Making Changes","text":"<ol> <li> <p>Write Code <pre><code># Follow existing code style\n# Add type hints\n# Write docstrings (Google style)\n</code></pre></p> </li> <li> <p>Run Tests <pre><code># Run all tests\nuv run python -m pytest\n\n# Run specific test\nuv run python -m pytest tests/test_loups.py::test_scan\n\n# With coverage\nuv run python -m pytest --cov=loups\n</code></pre></p> </li> <li> <p>Run Linters <pre><code># Format code\nblack loups tests\n\n# Check style\nflake8 loups tests\n\n# Sort imports\nisort loups tests\n\n# Or run all pre-commit hooks\ngit add .\ngit commit -m \"Your message\"  # Hooks run automatically\n</code></pre></p> </li> <li> <p>Test Manually <pre><code># Test CLI\nloups test_video.mp4\n\n# Test your changes\npython -c \"from loups import Loups; ...\"\n</code></pre></p> </li> </ol>"},{"location":"developer/contributing/#coding-standards","title":"Coding Standards","text":""},{"location":"developer/contributing/#python-style","title":"Python Style","text":"<p>Follow PEP 8 and project conventions:</p> <pre><code># Good example\ndef process_video_frame(\n    frame: np.ndarray,\n    template: np.ndarray,\n    threshold: float = 0.8\n) -&gt; Optional[MatchResult]:\n    \"\"\"Process video frame with template matching.\n\n    Args:\n        frame: Video frame as numpy array.\n        template: Template image for matching.\n        threshold: Minimum confidence threshold (0.0-1.0).\n\n    Returns:\n        MatchResult object if match found, None otherwise.\n\n    Raises:\n        ValueError: If threshold is not in valid range.\n\n    Examples:\n        ```python\n        result = process_video_frame(frame, template, 0.9)\n        if result:\n            print(f\"Match found with {result.confidence:.2f} confidence\")\n        ```\n    \"\"\"\n    if not 0.0 &lt;= threshold &lt;= 1.0:\n        raise ValueError(f\"Threshold must be 0.0-1.0, got {threshold}\")\n\n    # Implementation\n    match = match_template(frame, template)\n\n    if match.confidence &gt;= threshold:\n        return match\n\n    return None\n</code></pre>"},{"location":"developer/contributing/#docstring-requirements","title":"Docstring Requirements","text":"<p>D401: Imperative Mood Required</p> <p>All docstrings must start with imperative verb:</p>  Correct Incorrect <pre><code>def calculate_score():\n    \"\"\"Calculate similarity score.\"\"\"\n    pass\n</code></pre> <pre><code>def calculate_score():\n    \"\"\"Calculates similarity score.\"\"\"  # \u274c Present tense\n    pass\n\ndef calculate_score():\n    \"\"\"This function calculates...\"\"\"  # \u274c Not imperative\n    pass\n</code></pre>"},{"location":"developer/contributing/#type-hints","title":"Type Hints","text":"<p>Always use type hints:</p> <pre><code>from typing import List, Optional, Tuple\nimport numpy as np\n\ndef extract_frames(\n    video_path: str,\n    start_frame: int = 0,\n    end_frame: Optional[int] = None\n) -&gt; List[np.ndarray]:\n    \"\"\"Extract frames from video.\"\"\"\n    pass\n</code></pre>"},{"location":"developer/contributing/#example-names-in-docstrings","title":"Example Names in Docstrings","text":"<p>Use full names for batter examples (project requirement):</p> <pre><code># \u2705 Good\n\"\"\"\nExamples:\n    ```python\n    chapter = Chapter(\"0:05:23\", \"Sarah Johnson #7\")\n    ```\n\"\"\"\n\n# \u274c Bad\n\"\"\"\nExamples:\n    ```python\n    chapter = Chapter(\"0:05:23\", \"Sarah #7\")  # Missing last name\n    ```\n\"\"\"\n</code></pre>"},{"location":"developer/contributing/#testing-guidelines","title":"Testing Guidelines","text":""},{"location":"developer/contributing/#writing-tests","title":"Writing Tests","text":"<pre><code>import pytest\nfrom loups import Loups\n\nclass TestLoups:\n    \"\"\"Test suite for Loups class.\"\"\"\n\n    def test_initialization(self):\n        \"\"\"Test Loups initialization with valid parameters.\"\"\"\n        loups = Loups(\n            video_path=\"test.mp4\",\n            template_path=\"template.png\"\n        )\n\n        assert loups.video_path == \"test.mp4\"\n        assert loups.template_path == \"template.png\"\n\n    def test_initialization_invalid_video(self):\n        \"\"\"Test Loups initialization with invalid video path.\"\"\"\n        with pytest.raises(FileNotFoundError):\n            Loups(\n                video_path=\"nonexistent.mp4\",\n                template_path=\"template.png\"\n            )\n\n    @pytest.mark.parametrize(\"threshold\", [0.5, 0.8, 0.95])\n    def test_different_thresholds(self, threshold):\n        \"\"\"Test scanning with different confidence thresholds.\"\"\"\n        loups = Loups(\"test.mp4\", \"template.png\", threshold=threshold)\n        chapters = loups.scan()\n        assert isinstance(chapters, list)\n</code></pre>"},{"location":"developer/contributing/#test-fixtures","title":"Test Fixtures","text":"<pre><code># tests/conftest.py\nimport pytest\nfrom pathlib import Path\n\n@pytest.fixture\ndef test_video_path():\n    \"\"\"Provide path to test video.\"\"\"\n    return Path(__file__).parent / \"fixtures\" / \"test_video.mp4\"\n\n@pytest.fixture\ndef test_template_path():\n    \"\"\"Provide path to test template.\"\"\"\n    return Path(__file__).parent / \"fixtures\" / \"test_template.png\"\n\n# Usage in tests\ndef test_with_fixtures(test_video_path, test_template_path):\n    \"\"\"Test using fixtures.\"\"\"\n    loups = Loups(\n        video_path=str(test_video_path),\n        template_path=str(test_template_path)\n    )\n    assert loups is not None\n</code></pre>"},{"location":"developer/contributing/#running-tests","title":"Running Tests","text":"<pre><code># All tests\nuv run python -m pytest\n\n# Verbose\nuv run python -m pytest -v\n\n# Specific test file\nuv run python -m pytest tests/test_loups.py\n\n# Specific test function\nuv run python -m pytest tests/test_loups.py::test_initialization\n\n# With coverage report\nuv run python -m pytest --cov=loups --cov-report=html\n\n# Open coverage report\nopen htmlcov/index.html\n</code></pre>"},{"location":"developer/contributing/#git-commit-guidelines","title":"Git Commit Guidelines","text":""},{"location":"developer/contributing/#commit-message-format","title":"Commit Message Format","text":"<p>Follow Conventional Commits:</p> <pre><code>type(scope): description\n\n[optional body]\n\n[optional footer]\n</code></pre>"},{"location":"developer/contributing/#types","title":"Types","text":"Type Usage <code>feat</code> New feature <code>fix</code> Bug fix <code>docs</code> Documentation changes <code>style</code> Code style (formatting, no logic change) <code>refactor</code> Code restructuring (no feature/fix) <code>test</code> Adding/updating tests <code>chore</code> Build process, dependencies <code>perf</code> Performance improvements"},{"location":"developer/contributing/#examples","title":"Examples","text":"<pre><code># Feature\ngit commit -m \"feat(cli): add batch processing command\"\n\n# Bug fix\ngit commit -m \"fix(ocr): improve text extraction for low contrast frames\"\n\n# Documentation\ngit commit -m \"docs(api): add examples for Loups class usage\"\n\n# Refactoring\ngit commit -m \"refactor(core): simplify frame processing pipeline\"\n\n# Test\ngit commit -m \"test(thumbnail): add SSIM threshold edge cases\"\n\n# With body\ngit commit -m \"feat(cli): add progress bar for batch processing\n\nImplement rich progress bar that shows:\n- Current video being processed\n- Overall progress across all videos\n- Estimated time remaining\n\nCloses #123\"\n</code></pre>"},{"location":"developer/contributing/#material-pull-request-pull-request-process","title":":material-pull-request: Pull Request Process","text":""},{"location":"developer/contributing/#1-prepare-your-pr","title":"1. Prepare Your PR","text":"<pre><code># Make sure tests pass\nuv run python -m pytest\n\n# Make sure linting passes\nblack --check loups tests\nflake8 loups tests\nisort --check loups tests\n\n# Update your branch\ngit checkout main\ngit pull upstream main\ngit checkout your-feature-branch\ngit rebase main\n\n# Push to your fork\ngit push origin your-feature-branch\n</code></pre>"},{"location":"developer/contributing/#2-create-pull-request","title":"2. Create Pull Request","text":"<ol> <li>Go to https://github.com/jcspeegs/loups</li> <li>Click \"New Pull Request\"</li> <li>Select your fork and branch</li> <li>Fill in the PR template:</li> </ol> <pre><code>## Description\nBrief description of changes\n\n## Type of Change\n- [ ] Bug fix\n- [ ] New feature\n- [ ] Documentation update\n- [ ] Refactoring\n\n## Testing\n- [ ] Tests pass locally\n- [ ] Added new tests for changes\n- [ ] Manual testing performed\n\n## Checklist\n- [ ] Code follows project style\n- [ ] Docstrings added/updated\n- [ ] Documentation updated\n- [ ] No breaking changes (or documented)\n</code></pre>"},{"location":"developer/contributing/#3-code-review","title":"3. Code Review","text":"<ul> <li>Address reviewer feedback</li> <li>Push updates to same branch</li> <li>PR will update automatically</li> </ul> <pre><code># Make requested changes\n# ...\n\n# Commit and push\ngit add .\ngit commit -m \"fix: address review comments\"\ngit push origin your-feature-branch\n</code></pre>"},{"location":"developer/contributing/#4-merge","title":"4. Merge","text":"<p>Once approved: - Maintainer will merge your PR - Delete your branch - Celebrate! </p>"},{"location":"developer/contributing/#documentation_1","title":"Documentation","text":""},{"location":"developer/contributing/#building-docs-locally","title":"Building Docs Locally","text":"<pre><code># Serve documentation\ndevenv shell\ndocs  # or: mkdocs serve\n\n# Open in browser\nopen http://127.0.0.1:8000\n\n# Build static site\nmkdocs build\n\n# Output in site/ directory\n</code></pre>"},{"location":"developer/contributing/#documentation-style","title":"Documentation Style","text":"<ul> <li>Use clear, concise language</li> <li>Include code examples</li> <li>Add diagrams where helpful</li> <li>Use admonitions for important notes</li> </ul> <pre><code>!!! tip \"Pro Tip\"\n    Use `--quiet` flag for batch processing scripts!\n\n!!! warning \"Important\"\n    Options must come BEFORE the video path.\n\n!!! info \"Note\"\n    First run downloads OCR models (~100MB).\n</code></pre>"},{"location":"developer/contributing/#checklist-for-contributors","title":"Checklist for Contributors","text":"<p>Before submitting PR:</p> <ul> <li> Code follows PEP 8 and project style</li> <li> Type hints added to functions</li> <li> Docstrings added (Google style, imperative mood)</li> <li> Full names in batter examples</li> <li> Tests written and passing</li> <li> Linting passes (black, flake8, isort)</li> <li> Documentation updated</li> <li> Commit messages follow convention</li> <li> PR description filled out</li> <li> No breaking changes (or documented)</li> </ul>"},{"location":"developer/contributing/#questions","title":"Questions?","text":"<p>Need help?</p> <ul> <li> Open an issue</li> <li> Email maintainer</li> <li> Comment on existing issues/PRs</li> </ul>"},{"location":"developer/contributing/#recognition","title":"Recognition","text":"<p>Contributors are recognized in:</p> <ul> <li>GitHub contributors page</li> <li>Release notes</li> <li>Special thanks in documentation</li> </ul> <p>Thank you for contributing to Loups! </p>"},{"location":"developer/contributing/#additional-resources","title":"Additional Resources","text":"<ul> <li> Architecture - System design</li> <li> How It Works - Technical details</li> <li> API Reference - Code documentation</li> <li> GitHub Repository</li> </ul>"},{"location":"developer/how-it-works/","title":"How It Works","text":"<p>Deep dive into Loups' video processing pipeline and algorithms.</p>"},{"location":"developer/how-it-works/#processing-pipeline","title":"Processing Pipeline","text":"<p>Loups transforms videos into YouTube chapters through a 4-step process:</p> <pre><code>graph TB\n    subgraph \"Step 1: Template Matching\"\n        A1[Load Video] --&gt; A2[Load Template]\n        A2 --&gt; A3[Iterate Frames]\n        A3 --&gt; A4[cv2.matchTemplate]\n        A4 --&gt; A5{Confidence &gt;= Threshold?}\n        A5 --&gt;|Yes| A6[Record Match]\n        A5 --&gt;|No| A3\n        A6 --&gt; A3\n    end\n\n    subgraph \"Step 2: OCR Extraction\"\n        B1[For Each Match] --&gt; B2[Extract Frame Region]\n        B2 --&gt; B3[EasyOCR.readtext]\n        B3 --&gt; B4[Filter by Confidence]\n        B4 --&gt; B5[Sort Left-to-Right]\n        B5 --&gt; B6[Combine Text]\n    end\n\n    subgraph \"Step 3: Chapter Creation\"\n        C1[Match Data] --&gt; C2[Frame Number]\n        C2 --&gt; C3[Calculate Timestamp]\n        C3 --&gt; C4[Combine with OCR Text]\n        C4 --&gt; C5[Create Chapter Object]\n    end\n\n    subgraph \"Step 4: Output Generation\"\n        D1[All Chapters] --&gt; D2[Format as YouTube]\n        D2 --&gt; D3[HH:MM:SS Title]\n        D3 --&gt; D4[Display or Save]\n    end\n\n    A6 --&gt; B1\n    B6 --&gt; C1\n    C5 --&gt; D1\n\n    style A1 fill:#00ffff,stroke:#000,color:#000\n    style A4 fill:#00b8d4,stroke:#000,color:#fff\n    style B3 fill:#00b8d4,stroke:#000,color:#fff\n    style C3 fill:#00b8d4,stroke:#000,color:#fff\n    style D4 fill:#00ffff,stroke:#000,color:#000</code></pre>"},{"location":"developer/how-it-works/#step-1-template-matching","title":"Step 1: Template Matching","text":""},{"location":"developer/how-it-works/#what-is-template-matching","title":"What is Template Matching?","text":"<p>Template matching is a computer vision technique that finds regions in an image that match a template image.</p> <p>Analogy: Like using Ctrl+F to find text, but for images!</p>"},{"location":"developer/how-it-works/#algorithm-details","title":"Algorithm Details","text":"<p>Loups uses OpenCV's <code>cv2.matchTemplate</code> with the <code>TM_CCOEFF_NORMED</code> method:</p> <pre><code>import cv2\nimport numpy as np\n\ndef match_template(frame: np.ndarray, template: np.ndarray) -&gt; tuple:\n    \"\"\"\n    Match template against frame using normalized correlation.\n\n    Args:\n        frame: Video frame (BGR image).\n        template: Template image to match.\n\n    Returns:\n        (best_match_location, confidence_score)\n    \"\"\"\n    # Convert to grayscale for faster processing\n    frame_gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n    template_gray = cv2.cvtColor(template, cv2.COLOR_BGR2GRAY)\n\n    # Perform template matching\n    result = cv2.matchTemplate(\n        frame_gray,\n        template_gray,\n        cv2.TM_CCOEFF_NORMED\n    )\n\n    # Find best match\n    min_val, max_val, min_loc, max_loc = cv2.minMaxLoc(result)\n\n    # TM_CCOEFF_NORMED: higher is better\n    confidence = max_val\n    location = max_loc\n\n    return location, confidence\n</code></pre>"},{"location":"developer/how-it-works/#confidence-scoring","title":"Confidence Scoring","text":"Score Range Meaning Action 0.9 - 1.0  Exact match Always accept 0.7 - 0.9  Strong match Accept (default threshold: 0.8) 0.5 - 0.7  Moderate match Maybe accept (depends on use case) 0.0 - 0.5  Weak match Reject <p>Default threshold: <code>0.8</code> (strong match required)</p>"},{"location":"developer/how-it-works/#frame-iteration-strategy","title":"Frame Iteration Strategy","text":"<pre><code>cap = cv2.VideoCapture(video_path)\nfps = cap.get(cv2.CAP_PROP_FPS)\nframe_count = 0\n\nwhile True:\n    ret, frame = cap.read()\n    if not ret:\n        break\n\n    # Check every frame for maximum accuracy\n    # (Could skip frames for faster processing)\n    location, confidence = match_template(frame, template)\n\n    if confidence &gt;= threshold:\n        matches[frame_count] = {\n            'location': location,\n            'confidence': confidence,\n            'timestamp_ms': (frame_count / fps) * 1000\n        }\n\n    frame_count += 1\n\ncap.release()\n</code></pre>"},{"location":"developer/how-it-works/#why-tm_ccoeff_normed","title":"Why TM_CCOEFF_NORMED?","text":"<p>OpenCV offers 6 template matching methods. We use <code>TM_CCOEFF_NORMED</code> because:</p> <ul> <li> Normalized - Scores always 0.0 to 1.0</li> <li> Illumination-invariant - Robust to lighting changes</li> <li> Correlation-based - Measures similarity accurately</li> <li> Higher is better - Intuitive scoring</li> </ul>"},{"location":"developer/how-it-works/#step-2-ocr-extraction","title":"Step 2: OCR Extraction","text":""},{"location":"developer/how-it-works/#optical-character-recognition","title":"Optical Character Recognition","text":"<p>For each matched frame, we extract text using EasyOCR:</p> <pre><code>import easyocr\n\n# Initialize reader (done once)\nreader = easyocr.Reader(['en'], gpu=True)\n\ndef extract_text_from_region(frame: np.ndarray, region: tuple) -&gt; str:\n    \"\"\"\n    Extract text from specific frame region.\n\n    Args:\n        frame: Full video frame.\n        region: (x, y, width, height) bounding box.\n\n    Returns:\n        Extracted text string.\n    \"\"\"\n    x, y, w, h = region\n\n    # Crop to region of interest\n    roi = frame[y:y+h, x:x+w]\n\n    # Run OCR\n    results = reader.readtext(roi)\n\n    # Results format: [([box], text, confidence), ...]\n    # Filter by confidence and sort left-to-right\n    texts = []\n    for (box, text, confidence) in results:\n        if confidence &gt;= 0.6:  # Confidence threshold\n            texts.append((box[0][0], text))  # (x_position, text)\n\n    # Sort by x-position (left to right)\n    texts.sort(key=lambda t: t[0])\n\n    # Combine into single string\n    return ' '.join([text for _, text in texts])\n</code></pre>"},{"location":"developer/how-it-works/#confidence-filtering","title":"Confidence Filtering","text":"<p>OCR results include confidence scores (0.0 to 1.0):</p> <pre><code># Example OCR results\n[\n    ([[10, 20], [100, 20], [100, 50], [10, 50]], \"Sarah Johnson\", 0.95),\n    ([[110, 20], [140, 20], [140, 50], [110, 50]], \"#7\", 0.92),\n    ([[150, 20], [200, 20], [200, 50], [150, 50]], \"noise\", 0.35),  # Filtered out\n]\n\n# After filtering (confidence &gt;= 0.6)\n\"Sarah Johnson #7\"\n</code></pre>"},{"location":"developer/how-it-works/#arrows_left_right-left-to-right-sorting","title":":arrows_left_right: Left-to-Right Sorting","text":"<p>OCR can return text in any order. We sort by x-coordinate:</p> <pre><code>def sort_text_left_to_right(ocr_results: list) -&gt; str:\n    \"\"\"Sort OCR results by horizontal position.\"\"\"\n    # Extract x-coordinate from first corner of bounding box\n    texts_with_position = [\n        (bbox[0][0], text)  # bbox[0][0] is top-left x-coordinate\n        for bbox, text, confidence in ocr_results\n        if confidence &gt;= 0.6\n    ]\n\n    # Sort by x-position\n    texts_with_position.sort(key=lambda t: t[0])\n\n    # Return combined text\n    return ' '.join([text for _, text in texts_with_position])\n</code></pre> <p>Example:</p> <pre><code>Frame contains:\n  [Position 100] \"#7\"\n  [Position 10] \"Sarah Johnson\"\n\nAfter sorting:\n  \"Sarah Johnson #7\"  \u2705\n</code></pre>"},{"location":"developer/how-it-works/#step-3-chapter-creation","title":"Step 3: Chapter Creation","text":""},{"location":"developer/how-it-works/#timestamp-calculation","title":"Timestamp Calculation","text":"<p>Convert frame number to YouTube timestamp:</p> <pre><code>class MilliSecond:\n    \"\"\"Convert milliseconds to YouTube format.\"\"\"\n\n    def __init__(self, ms: int):\n        self.ms = ms\n\n    def yt_format(self) -&gt; str:\n        \"\"\"Format as HH:MM:SS or MM:SS.\"\"\"\n        total_seconds = self.ms // 1000\n        hours = total_seconds // 3600\n        minutes = (total_seconds % 3600) // 60\n        seconds = total_seconds % 60\n\n        if hours &gt; 0:\n            return f\"{hours:01d}:{minutes:02d}:{seconds:02d}\"\n        else:\n            return f\"{minutes:01d}:{seconds:02d}\"\n\n# Usage\nframe_num = 150\nfps = 30.0\ntimestamp_ms = (frame_num / fps) * 1000  # 5000 ms\n\nms = MilliSecond(int(timestamp_ms))\nprint(ms.yt_format())  # \"0:05\"\n</code></pre>"},{"location":"developer/how-it-works/#chapter-object","title":"Chapter Object","text":"<pre><code>from dataclasses import dataclass\n\n@dataclass\nclass Chapter:\n    \"\"\"Represents a video chapter.\"\"\"\n    timestamp: str      # YouTube format \"HH:MM:SS\"\n    title: str          # OCR extracted text\n    frame_number: int   # Original frame number\n    milliseconds: int   # Timestamp in ms\n    confidence: float   # Template match confidence\n\n# Example\nchapter = Chapter(\n    timestamp=\"0:05:23\",\n    title=\"Sarah Johnson #7\",\n    frame_number=9690,\n    milliseconds=323000,\n    confidence=0.94\n)\n</code></pre>"},{"location":"developer/how-it-works/#step-4-output-generation","title":"Step 4: Output Generation","text":""},{"location":"developer/how-it-works/#youtube-chapter-format","title":"YouTube Chapter Format","text":"<p>YouTube requires specific format:</p> <pre><code>HH:MM:SS Chapter Title\n</code></pre> <p>or for videos under 1 hour:</p> <pre><code>MM:SS Chapter Title\n</code></pre> <p>Rules: - Timestamps in ascending order - First chapter at 0:00:00 (or 0:00) - No duplicate timestamps - One chapter per line</p>"},{"location":"developer/how-it-works/#output-generation","title":"Output Generation","text":"<pre><code>def format_chapters_for_youtube(chapters: List[Chapter]) -&gt; str:\n    \"\"\"Format chapters for YouTube description.\"\"\"\n    lines = []\n\n    # Ensure starts at 0:00\n    if not chapters or chapters[0].milliseconds &gt; 0:\n        lines.append(\"0:00 Introduction\")\n\n    # Add all chapters\n    for chapter in chapters:\n        lines.append(f\"{chapter.timestamp} {chapter.title}\")\n\n    return '\\n'.join(lines)\n\n# Example output:\n\"\"\"\n0:00 Introduction\n0:05:23 Sarah Johnson #7\n0:08:45 Emma Martinez #12\n0:12:30 Lily Garcia #9\n\"\"\"\n</code></pre>"},{"location":"developer/how-it-works/#display-with-rich","title":"Display with Rich","text":"<pre><code>from rich.console import Console\nfrom rich.table import Table\n\nconsole = Console()\n\ndef display_chapters(chapters: List[Chapter]):\n    \"\"\"Display chapters in beautiful table.\"\"\"\n    table = Table(title=\"\ud83e\udd4e Video Chapters\")\n\n    table.add_column(\"Timestamp\", style=\"cyan\")\n    table.add_column(\"Title\", style=\"white\")\n    table.add_column(\"Confidence\", style=\"green\")\n\n    for chapter in chapters:\n        table.add_row(\n            chapter.timestamp,\n            chapter.title,\n            f\"{chapter.confidence:.2%}\"\n        )\n\n    console.print(table)\n</code></pre>"},{"location":"developer/how-it-works/#thumbnail-extraction-ssim","title":"Thumbnail Extraction (SSIM)","text":"<p>Separate process using SSIM instead of template matching:</p> <pre><code>from skimage.metrics import structural_similarity as ssim\nimport cv2\n\ndef extract_thumbnail(\n    video_path: str,\n    template_path: str,\n    threshold: float = 0.35\n) -&gt; str:\n    \"\"\"Extract thumbnail using SSIM matching.\"\"\"\n\n    # Load template\n    template = cv2.imread(template_path)\n    template_h, template_w = template.shape[:2]\n\n    cap = cv2.VideoCapture(video_path)\n    fps = cap.get(cv2.CAP_PROP_FPS)\n    sample_interval = int(fps / 3)  # Sample 3 FPS\n\n    frame_count = 0\n\n    while True:\n        ret, frame = cap.read()\n        if not ret:\n            break\n\n        # Sample every Nth frame\n        if frame_count % sample_interval != 0:\n            frame_count += 1\n            continue\n\n        # Resize frame to template size\n        frame_resized = cv2.resize(frame, (template_w, template_h))\n\n        # Calculate SSIM\n        score = ssim(template, frame_resized, multichannel=True)\n\n        # Check threshold\n        if score &gt;= threshold:\n            # Found match!\n            output_path = \"thumbnail.jpg\"\n            cv2.imwrite(output_path, frame)\n            cap.release()\n            return output_path\n\n        frame_count += 1\n\n    cap.release()\n    raise ValueError(\"No matching thumbnail found\")\n</code></pre>"},{"location":"developer/how-it-works/#ssim-vs-template-matching","title":"SSIM vs Template Matching","text":"Feature Template Matching SSIM Purpose Find regions in frame Compare full frames Output Bounding box location Similarity score (0-1) Speed Faster Moderate Accuracy High for patterns High for images Use Case Chapter detection Thumbnail matching <p>Why SSIM for thumbnails? - Compares entire frame composition - Accounts for structural similarity - Robust to minor color/lighting changes - Perceptually meaningful metric</p>"},{"location":"developer/how-it-works/#performance-optimizations","title":"Performance Optimizations","text":""},{"location":"developer/how-it-works/#frame-skipping","title":"Frame Skipping","text":"<pre><code># Check every Nth frame for faster processing\nskip_frames = 5\n\nframe_count = 0\nwhile True:\n    ret, frame = cap.read()\n    if not ret:\n        break\n\n    if frame_count % skip_frames == 0:\n        # Process this frame\n        match_template(frame, template)\n\n    frame_count += 1\n</code></pre> <p>Trade-off: Speed vs. Accuracy - Skip more frames = faster, might miss detections - Check all frames = slower, maximum accuracy</p>"},{"location":"developer/how-it-works/#grayscale-conversion","title":"Grayscale Conversion","text":"<pre><code># Template matching faster in grayscale\nframe_gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\ntemplate_gray = cv2.cvtColor(template, cv2.COLOR_BGR2GRAY)\n\n# 3x faster than color matching\nresult = cv2.matchTemplate(frame_gray, template_gray, cv2.TM_CCOEFF_NORMED)\n</code></pre>"},{"location":"developer/how-it-works/#gpu-acceleration","title":"GPU Acceleration","text":"<pre><code># EasyOCR can use GPU\nreader = easyocr.Reader(['en'], gpu=True)  # Enable GPU\n\n# Significant speedup on systems with CUDA GPUs\n</code></pre>"},{"location":"developer/how-it-works/#template-size","title":"Template Size","text":"<pre><code># Smaller templates = faster matching\n# Resize template if very large\nmax_template_width = 800\n\nif template.shape[1] &gt; max_template_width:\n    scale = max_template_width / template.shape[1]\n    template = cv2.resize(template, None, fx=scale, fy=scale)\n</code></pre>"},{"location":"developer/how-it-works/#edge-cases-error-handling","title":"Edge Cases &amp; Error Handling","text":""},{"location":"developer/how-it-works/#no-matches-found","title":"No Matches Found","text":"<pre><code>if not matches:\n    logger.warning(\"No template matches found in video\")\n    return [Chapter(\n        timestamp=\"0:00\",\n        title=\"No chapters detected\",\n        frame_number=0,\n        milliseconds=0,\n        confidence=0.0\n    )]\n</code></pre>"},{"location":"developer/how-it-works/#duplicate-detections","title":"Duplicate Detections","text":"<pre><code># Filter out matches within same time window\nMIN_TIME_BETWEEN_MATCHES = 5000  # 5 seconds in milliseconds\n\nfiltered_matches = []\nlast_timestamp = -MIN_TIME_BETWEEN_MATCHES\n\nfor match in sorted_matches:\n    if match.milliseconds - last_timestamp &gt;= MIN_TIME_BETWEEN_MATCHES:\n        filtered_matches.append(match)\n        last_timestamp = match.milliseconds\n</code></pre>"},{"location":"developer/how-it-works/#ocr-failures","title":"OCR Failures","text":"<pre><code>try:\n    text = extract_text(frame_region)\nexcept Exception as e:\n    logger.error(f\"OCR failed for frame {frame_num}: {e}\")\n    text = f\"Chapter {frame_num}\"  # Fallback title\n</code></pre>"},{"location":"developer/how-it-works/#related-documentation","title":"Related Documentation","text":"<ul> <li> Architecture - System design</li> <li> API Reference - Code documentation</li> <li> CLI Reference - Command usage</li> </ul>"},{"location":"includes/snippets/","title":"Snippets","text":"<pre><code>Scanning video: game_video.mp4\n\n\ud83e\udd4e Scanning batters...  [Progress updates]\n\n\ud83c\udfc6 Scan complete! Found 12 batters in 5.2s\n\nYouTube Chapters:\n0:00:00 Game Start\n0:01:15 Sarah Johnson #7\n0:03:42 Emma Martinez #12\n0:05:23 Lily Garcia #9\n0:08:14 Olivia Brown #5\n...\n</code></pre>"},{"location":"user-guide/","title":"User Guide","text":"<p>Welcome to the Loups user guide! This section covers everything you need to know to use Loups effectively.</p>"},{"location":"user-guide/#navigation","title":"Navigation","text":""},{"location":"user-guide/#installation","title":"Installation","text":"<p>Get Loups installed on your system with Python 3.13+</p>"},{"location":"user-guide/#quick-start","title":"Quick Start","text":"<p>Start scanning videos and generating chapters in minutes</p>"},{"location":"user-guide/#cli-reference","title":"CLI Reference","text":"<p>Complete command-line interface documentation</p>"},{"location":"user-guide/#custom-templates","title":"Custom Templates","text":"<p>Create templates for any video content</p>"},{"location":"user-guide/#quick-example","title":"Quick Example","text":"<pre><code># Install\npip install loups\n\n# Scan a video\nloups game_video.mp4\n\n# Save chapters to file\nloups -o chapters.txt video.mp4\n\n# Use custom template\nloups -t my_template.png video.mp4\n</code></pre>"},{"location":"user-guide/#common-workflows","title":"Common Workflows","text":""},{"location":"user-guide/#creating-youtube-chapters","title":"Creating YouTube Chapters","text":"<ol> <li>Install Loups</li> <li>Create or use existing template</li> <li>Scan your video: <code>loups -o chapters.txt video.mp4</code></li> <li>Copy <code>chapters.txt</code> content to YouTube description</li> </ol>"},{"location":"user-guide/#extracting-thumbnails","title":"Extracting Thumbnails","text":"<ol> <li>Use thumbnail subcommand: <code>loups video.mp4 thumbnail</code></li> <li>Or extract during scanning: <code>loups --extract-thumbnail video.mp4</code></li> <li>Upload thumbnail to YouTube</li> </ol>"},{"location":"user-guide/#batch-processing","title":"Batch Processing","text":"<p>Use quiet mode for automation:</p> <pre><code>for video in *.mp4; do\n  loups -q -o \"${video%.mp4}_chapters.txt\" \"$video\"\ndone\n</code></pre>"},{"location":"user-guide/#need-help","title":"Need Help?","text":"<ul> <li> Report issues on GitHub</li> <li> Contact the author</li> <li> Read the full documentation</li> </ul>"},{"location":"user-guide/cli-reference/","title":"CLI Reference","text":"<p>Complete command-line interface documentation for Loups.</p>"},{"location":"user-guide/cli-reference/#command-structure","title":"Command Structure","text":"<pre><code>graph TD\n    A[loups] --&gt; B{Command Type}\n    B --&gt;|Default| C[Scan for Chapters]\n    B --&gt;|thumbnail| D[Extract Thumbnail]\n\n    C --&gt; C1[loups OPTIONS VIDEO]\n    C1 --&gt; C2[Process video with template matching]\n    C2 --&gt; C3[Generate YouTube chapters]\n\n    D --&gt; D1[loups VIDEO thumbnail OPTIONS]\n    D1 --&gt; D2[SSIM-based thumbnail extraction]\n    D2 --&gt; D3[Save thumbnail JPEG]\n\n    style A fill:#00ffff,stroke:#000,color:#000\n    style B fill:#00b8d4,stroke:#000,color:#000\n    style C fill:#00ffff,stroke:#000,color:#fff\n    style D fill:#00ffff,stroke:#000,color:#fff\n    style C3 fill:#00ffff,stroke:#000,color:#000\n    style D3 fill:#00ffff,stroke:#000,color:#000</code></pre> <p>Syntax Differences</p> <ul> <li>Main command: <code>loups [OPTIONS] VIDEO</code> - Options BEFORE video</li> <li>Thumbnail command: <code>loups VIDEO thumbnail [OPTIONS]</code> - Video BEFORE options</li> </ul>"},{"location":"user-guide/cli-reference/#main-command-chapter-scanning","title":"Main Command: Chapter Scanning","text":"<p>Scan video for chapters using template matching and OCR.</p>"},{"location":"user-guide/cli-reference/#syntax","title":"Syntax","text":"<pre><code>loups [OPTIONS] VIDEO\n</code></pre>"},{"location":"user-guide/cli-reference/#required-arguments","title":"Required Arguments","text":"Argument Description <code>VIDEO</code>  Path to video file (must come AFTER options)"},{"location":"user-guide/cli-reference/#optional-flags","title":"Optional Flags","text":""},{"location":"user-guide/cli-reference/#template-output","title":"Template &amp; Output","text":"Flag Short Type Description <code>--template PATH</code> <code>-t</code> Path  Template image for detectionDefault: Bundled Lights Out HB templateUse: Provide custom template for any video <code>--output PATH</code> <code>-o</code> Path  Save results to file in YouTube formatFormat: <code>HH:MM:SS Chapter Title</code> per line"},{"location":"user-guide/cli-reference/#logging-debug","title":"Logging &amp; Debug","text":"Flag Short Type Description <code>--log [PATH]</code> <code>-l</code> Path  Enable loggingDefault: <code>loups.log</code> in current directoryRotation: 10MB max, 3 backup files <code>--debug</code> <code>-d</code> Flag  Enable DEBUG level loggingRequires: <code>--log</code> flagUse: Troubleshoot detection issues <code>--quiet</code> <code>-q</code> Flag  Suppress progress displayNote: Errors still shownUse: Automation/scripting"},{"location":"user-guide/cli-reference/#thumbnail-options-during-scan","title":"Thumbnail Options (During Scan)","text":"Flag Type Description <code>--extract-thumbnail</code> Flag  Extract thumbnail during scan <code>--thumbnail-template PATH</code> Path  Template for thumbnail matchingDefault: Uses bundled template <code>--thumbnail-output PATH</code> Path  Thumbnail save locationDefault: <code>&lt;video&gt;-thumbnail.jpg</code> <code>--thumbnail-threshold FLOAT</code> 0.0-1.0  SSIM similarity thresholdDefault: 0.35Range: 0.0 (loose) to 1.0 (exact) <code>--thumbnail-scan-duration INT</code> Seconds  Max seconds to scan from startDefault: 120 seconds <code>--thumbnail-frames-per-second INT</code> FPS  Frame sampling rateDefault: 3 FPS"},{"location":"user-guide/cli-reference/#examples","title":"Examples","text":""},{"location":"user-guide/cli-reference/#basic-usage","title":"Basic Usage","text":"<pre><code># Use bundled template (Lights Out HB)\nloups game_video.mp4\n\n# Custom template\nloups -t scoreboard.png video.mp4\n\n# Save to file\nloups -o chapters.txt video.mp4\n\n# Custom template + save\nloups -t template.png -o chapters.txt video.mp4\n</code></pre>"},{"location":"user-guide/cli-reference/#logging-debug_1","title":"Logging &amp; Debug","text":"<pre><code># Enable default logging\nloups --log video.mp4\n\n# Custom log file\nloups --log /tmp/debug.log video.mp4\n\n# Debug mode for troubleshooting\nloups --log --debug video.mp4\n</code></pre>"},{"location":"user-guide/cli-reference/#quiet-mode","title":"Quiet Mode","text":"<pre><code># Suppress progress (for scripts)\nloups -q -o chapters.txt video.mp4\n\n# Combine with logging\nloups -q --log --debug -o output.txt video.mp4\n</code></pre>"},{"location":"user-guide/cli-reference/#combined-with-thumbnail","title":"Combined with Thumbnail","text":"<pre><code># Extract thumbnail during scan\nloups --extract-thumbnail -o chapters.txt video.mp4\n\n# Custom thumbnail settings\nloups --extract-thumbnail \\\n      --thumbnail-template title.png \\\n      --thumbnail-output thumb.jpg \\\n      --thumbnail-threshold 0.5 \\\n      -o chapters.txt \\\n      video.mp4\n</code></pre>"},{"location":"user-guide/cli-reference/#thumbnail-command","title":"Thumbnail Command","text":"<p>Extract thumbnail using SSIM-based template matching.</p>"},{"location":"user-guide/cli-reference/#syntax_1","title":"Syntax","text":"<pre><code>loups VIDEO thumbnail [OPTIONS]\n</code></pre> <p>Note the Order</p> <p>Unlike the main command, <code>VIDEO</code> comes BEFORE the <code>thumbnail</code> keyword.</p>"},{"location":"user-guide/cli-reference/#required-arguments_1","title":"Required Arguments","text":"Argument Description <code>VIDEO</code>  Path to video file <code>thumbnail</code> Subcommand keyword"},{"location":"user-guide/cli-reference/#optional-flags_1","title":"Optional Flags","text":"Flag Type Description <code>--thumbnail-template PATH</code> Path  Template image for matchingDefault: Bundled template <code>--thumbnail-output PATH</code> Path  Output file pathDefault: <code>&lt;video&gt;-thumbnail.jpg</code> in cwd <code>--thumbnail-threshold FLOAT</code> 0.0-1.0  SSIM similarity thresholdDefault: 0.35 <code>--thumbnail-scan-duration INT</code> Seconds  Max seconds to scanDefault: 120 <code>--thumbnail-frames-per-second INT</code> FPS  Frame sampling rateDefault: 3 <code>--quiet</code> Flag  Suppress output"},{"location":"user-guide/cli-reference/#examples_1","title":"Examples","text":""},{"location":"user-guide/cli-reference/#basic-thumbnail-extraction","title":"Basic Thumbnail Extraction","text":"<pre><code># Use default settings\nloups video.mp4 thumbnail\n\n# Custom output location\nloups video.mp4 thumbnail --thumbnail-output ./thumbnails/game1.jpg\n\n# Custom template\nloups video.mp4 thumbnail --thumbnail-template title_screen.png\n</code></pre>"},{"location":"user-guide/cli-reference/#advanced-thumbnail-settings","title":"Advanced Thumbnail Settings","text":"<pre><code># Stricter matching (higher threshold)\nloups video.mp4 thumbnail --thumbnail-threshold 0.7\n\n# Scan longer duration\nloups video.mp4 thumbnail --thumbnail-scan-duration 300\n\n# Sample more frames per second\nloups video.mp4 thumbnail --thumbnail-frames-per-second 5\n</code></pre>"},{"location":"user-guide/cli-reference/#batch-thumbnail-extraction","title":"Batch Thumbnail Extraction","text":"<pre><code># Process multiple videos\nfor video in *.mp4; do\n  loups \"$video\" thumbnail --thumbnail-output \"thumbs/${video%.mp4}.jpg\"\ndone\n</code></pre>"},{"location":"user-guide/cli-reference/#tips-best-practices","title":"Tips &amp; Best Practices","text":""},{"location":"user-guide/cli-reference/#option-order","title":"Option Order","text":"<p>Correct Order</p> <pre><code>loups [OPTIONS] VIDEO          # Main command\nloups VIDEO thumbnail [OPTIONS] # Thumbnail command\n</code></pre> <p>Incorrect Order</p> <pre><code>loups VIDEO [OPTIONS]           # Won't work!\nloups thumbnail VIDEO [OPTIONS] # Won't work!\n</code></pre>"},{"location":"user-guide/cli-reference/#template-quality","title":"Template Quality","text":"<p>Good Templates</p> <ul> <li> High contrast, clear text</li> <li> Consistent position in video</li> <li> No motion blur</li> <li> Tightly cropped around target</li> </ul> <p>Poor Templates</p> <ul> <li> Blurry or low resolution</li> <li> Includes moving elements</li> <li> Too large (includes extra regions)</li> <li> Inconsistent across video</li> </ul>"},{"location":"user-guide/cli-reference/#logging-strategies","title":"Logging Strategies","text":"Troubleshooting Production Automation <pre><code># Full debug logging\nloups --log debug.log --debug -t template.png video.mp4\n\n# Check the log\ntail -f debug.log\n</code></pre> <pre><code># Quiet mode, log errors only\nloups -q --log errors.log video.mp4\n</code></pre> <pre><code># Minimal output, errors to log\nloups -q --log /var/log/loups.log -o output.txt video.mp4\n</code></pre>"},{"location":"user-guide/cli-reference/#exit-codes","title":"Exit Codes","text":"Code Meaning <code>0</code>  Success <code>1</code>  Error occurred <code>2</code>  Invalid arguments <p>Use in scripts:</p> <pre><code>if loups -q -o chapters.txt video.mp4; then\n  echo \"Success!\"\nelse\n  echo \"Failed with exit code $?\"\nfi\n</code></pre>"},{"location":"user-guide/cli-reference/#related-pages","title":"Related Pages","text":"<ul> <li> Quick Start - Get started quickly</li> <li> Custom Templates - Create templates</li> <li> API Reference - Programmatic usage</li> </ul>"},{"location":"user-guide/custom-templates/","title":"Creating Custom Templates","text":"<p>Learn how to create templates for any video content to use with Loups.</p>"},{"location":"user-guide/custom-templates/#what-is-a-template","title":"What is a Template?","text":"<p>A template is an image that acts as a trigger - Loups scans your video looking for frames that match this template. When a match is found, Loups extracts the text from that frame to create a chapter entry.</p> <p>Template Analogy</p> <p>Think of the template as a \"bookmark shape\" - Loups flips through your video looking for frames that look like your bookmark. When it finds one, it reads the text on that page.</p>"},{"location":"user-guide/custom-templates/#4-step-process","title":"4-Step Process","text":""},{"location":"user-guide/custom-templates/#find-a-clear-frame","title":"Find a Clear Frame","text":"<p>Pause your video where the identifying text overlay is clearly visible:</p> <ul> <li>Sports: Scoreboard with player name</li> <li>Podcasts: Guest name overlay</li> <li>Gaming: Level title card</li> <li>Educational: Speaker introduction</li> </ul> <p>Best Practices</p> <ul> <li> Text is fully visible and readable</li> <li> No motion blur</li> <li> Consistent lighting</li> <li> Frame appears multiple times in video</li> </ul>"},{"location":"user-guide/custom-templates/#take-a-screenshot","title":"Take a Screenshot","text":"<p>Capture the frame:</p>  macOS Windows Linux <ul> <li>Press <code>\u2318</code> + <code>Shift</code> + <code>4</code></li> <li>Select area to capture</li> <li>File saved to Desktop</li> </ul> <ul> <li>Press <code>Win</code> + <code>Shift</code> + <code>S</code></li> <li>Select area</li> <li>Save from clipboard</li> </ul> <ul> <li>Use screenshot tool</li> <li>Or: <code>gnome-screenshot -a</code></li> </ul>"},{"location":"user-guide/custom-templates/#crop-the-template","title":"Crop the Template","text":"<p>Open in image editor and crop to include:</p> <ul> <li> The region where text appears</li> <li> Some surrounding context (helps matching)</li> <li> Exclude elements that change frame-to-frame</li> </ul> <p>Crop Carefully</p> <p>Too large: May include changing elements \u2192 false negatives Too small: May not match reliably \u2192 missed detections</p> <p>Just right: Includes text region + stable surrounding area</p>"},{"location":"user-guide/custom-templates/#save-and-use","title":"Save and Use","text":"<p>Save as PNG (recommended) or JPG:</p> <pre><code>loups -t my_template.png video.mp4\n</code></pre>"},{"location":"user-guide/custom-templates/#template-examples","title":"Template Examples","text":""},{"location":"user-guide/custom-templates/#sports-scoreboard","title":"Sports Scoreboard","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502  BATTER: Sarah Johnson #7   \u2502  \u2190 Include this\n\u2502  INNING: 3   SCORE: 2-1     \u2502  \u2190 Crop around text\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> <p>What to include: - Player name area - Jersey number location - Stable background elements</p> <p>What to exclude: - Changing score - Moving elements - Video timestamp</p>"},{"location":"user-guide/custom-templates/#podcast-guest-overlay","title":"Podcast Guest Overlay","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502  NOW SPEAKING:       \u2502\n\u2502  Dr. Jane Smith      \u2502  \u2190 Crop this region\n\u2502  AI Researcher       \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> <p>What to include: - Name card background - \"NOW SPEAKING\" label if consistent - Text region</p>"},{"location":"user-guide/custom-templates/#game-level-card","title":"Game Level Card","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502  LEVEL 5        \u2502  \u2190 Level text\n\u2502  The Castle     \u2502  \u2190 Level name\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> <p>What to include: - Level indicator - Title text area - Consistent UI elements</p>"},{"location":"user-guide/custom-templates/#template-quality-checklist","title":"Template Quality Checklist","text":"<p>Good Template Characteristics</p> <ul> <li> High contrast - Text clearly visible</li> <li> Consistent position - Same location throughout video</li> <li> Clear text - No blur, pixelation, or distortion</li> <li> Stable background - Unchanging elements</li> <li> Appropriate size - Not too large, not too small</li> <li> Good resolution - Match video quality</li> </ul> <p>Avoid These Issues</p> <ul> <li>  Motion blur or partial frames</li> <li>  Changing elements (scores, timers)</li> <li>  Low resolution or compression artifacts</li> <li>  Text partially cut off</li> <li>  Inconsistent appearance across video</li> </ul>"},{"location":"user-guide/custom-templates/#testing-your-template","title":"Testing Your Template","text":""},{"location":"user-guide/custom-templates/#step-1-test-on-short-clip","title":"Step 1: Test on Short Clip","text":"<p>Create a test clip first:</p> <pre><code># Extract first 2 minutes with ffmpeg\nffmpeg -i full_video.mp4 -t 120 -c copy test_clip.mp4\n</code></pre>"},{"location":"user-guide/custom-templates/#step-2-run-with-logging","title":"Step 2: Run with Logging","text":"<pre><code>loups --log --debug -t my_template.png test_clip.mp4\n</code></pre>"},{"location":"user-guide/custom-templates/#step-3-check-results","title":"Step 3: Check Results","text":"<pre><code># View the log\ncat loups.log\n\n# Look for:\n# - Template match timestamps\n# - OCR confidence scores\n# - Extracted text\n</code></pre>"},{"location":"user-guide/custom-templates/#step-4-adjust-if-needed","title":"Step 4: Adjust if Needed","text":"<p>Troubleshooting</p> <p>Too many matches? \u2192 Crop template more tightly Missing matches? \u2192 Include more surrounding context Wrong text extracted? \u2192 Adjust template boundaries Garbled OCR? \u2192 Use higher quality source frame</p>"},{"location":"user-guide/custom-templates/#advanced-tips","title":"Advanced Tips","text":""},{"location":"user-guide/custom-templates/#multiple-templates","title":"Multiple Templates","text":"<p>Can't find one template that works for all frames? Use different templates:</p> <pre><code># Process same video multiple times with different templates\nloups -t template1.png -o chapters1.txt video.mp4\nloups -t template2.png -o chapters2.txt video.mp4\n\n# Combine results manually\ncat chapters1.txt chapters2.txt | sort &gt; all_chapters.txt\n</code></pre>"},{"location":"user-guide/custom-templates/#template-for-thumbnails","title":"Template for Thumbnails","text":"<p>Create a separate template for thumbnail extraction:</p> <pre><code># Different template for title screen\nloups video.mp4 thumbnail --thumbnail-template title_screen_template.png\n</code></pre>"},{"location":"user-guide/custom-templates/#video-quality-matters","title":"Video Quality Matters","text":"<p>Source Quality</p> <p>Template matching works best with:</p> <ul> <li>720p or higher video resolution</li> <li>Minimal compression artifacts</li> <li>Steady camera (for handheld footage)</li> <li>Good lighting and contrast</li> </ul>"},{"location":"user-guide/custom-templates/#use-case-examples","title":"Use Case Examples","text":""},{"location":"user-guide/custom-templates/#educational-lecture","title":"Educational Lecture","text":"<p>Scenario: Video with speaker name overlays</p> <pre><code>Template includes:\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 \ud83d\udc64 Speaker Name     \u2502\n\u2502    Title/Role       \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> <p>Result: <pre><code>0:00:00 Introduction\n0:05:30 Dr. Sarah Chen - Computer Science\n0:25:15 Prof. Michael Brown - Mathematics\n0:45:00 Dr. Lisa Wang - Physics\n</code></pre></p>"},{"location":"user-guide/custom-templates/#music-performance","title":"Music Performance","text":"<p>Scenario: Song title cards between performances</p> <pre><code>Template includes:\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502  \ud83c\udfb5 Now Playing:     \u2502\n\u2502  [Song Title]        \u2502\n\u2502  [Artist Name]       \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> <p>Result: <pre><code>0:00:00 Opening\n0:03:45 Song Title - Artist Name\n0:08:20 Another Song - Different Artist\n</code></pre></p>"},{"location":"user-guide/custom-templates/#tv-series","title":"TV Series","text":"<p>Scenario: Episode title cards</p> <pre><code>Template includes:\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502  EPISODE 5         \u2502\n\u2502  \"Episode Title\"   \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"user-guide/custom-templates/#tools-for-template-creation","title":"Tools for Template Creation","text":""},{"location":"user-guide/custom-templates/#recommended-tools","title":"Recommended Tools","text":"Tool Platform Free Use Case Preview  macOS Built-in, simple cropping Paint  Windows Basic editing GIMP  All Advanced editing ffmpeg  All Extract frames VLC  All Screenshot frames"},{"location":"user-guide/custom-templates/#extract-frame-with-ffmpeg","title":"Extract Frame with ffmpeg","text":"<p>Get a perfect frame from exact timestamp:</p> <pre><code># Extract frame at 01:23:45\nffmpeg -ss 01:23:45 -i video.mp4 -frames:v 1 template.png\n</code></pre>"},{"location":"user-guide/custom-templates/#next-steps","title":"Next Steps","text":"<p>Now that you have a template:</p> <ol> <li> Quick Start - Use your template</li> <li> CLI Reference - Template options</li> <li> API Reference - Programmatic usage</li> </ol>"},{"location":"user-guide/custom-templates/#common-questions","title":"Common Questions","text":"Can I use the same template for different videos? <p>Yes, if the videos have the same overlay/UI format!</p> <p>For example: - All episodes of same TV series - Same game with consistent UI - Videos from same production</p> What image format should I use? <p>PNG recommended for best quality (lossless compression)</p> <p>Also supported: - JPG/JPEG (acceptable, slightly lower quality) - BMP (works but larger files)</p> Does template size matter? <p>Yes! Template should be:</p> <ul> <li>Same resolution as video (or close)</li> <li>Large enough to be distinctive</li> <li>Small enough to avoid changing elements</li> </ul> <p>Typically 200-800 pixels wide works well.</p> Can I create templates from YouTube videos? <p>Absolutely! Take screenshots while watching:</p> <ul> <li>Pause at the overlay you want</li> <li>Screenshot the browser window</li> <li>Crop to just the overlay region</li> <li>Use with downloaded video file</li> </ul> My template isn't matching. What now? <p>Try these steps:</p> <ol> <li>Enable debug logging: <code>loups --log --debug -t template.png video.mp4</code></li> <li>Check the log for match confidence scores</li> <li>Verify template matches video frames exactly</li> <li>Adjust crop - try larger/smaller regions</li> <li>Check resolution - template should match video quality</li> </ol> <p>Still stuck? Open an issue with: - Sample frame from video - Your template image - Debug log output</p>"},{"location":"user-guide/installation/","title":"Installation","text":"<p>Get Loups installed and running on your system.</p>"},{"location":"user-guide/installation/#system-requirements","title":"System Requirements","text":"<p>Python Version Required</p> <p>Python 3.13 or higher is required.</p> <p>Loups uses modern Python features and requires Python 3.13+.</p>"},{"location":"user-guide/installation/#supported-platforms","title":"Supported Platforms","text":"Platform Status Tested Linux  Fully Supported  CI/CD macOS  Fully Supported  CI/CD Windows  Fully Supported  CI/CD"},{"location":"user-guide/installation/#installation-methods","title":"Installation Methods","text":"pip (Recommended) uv pipx (Isolated) <p>The easiest way to install Loups is via pip:</p> <pre><code>pip install loups\n</code></pre> <p>Verify installation:</p> <pre><code>loups --help\n</code></pre> <p>Using the modern uv package manager:</p> <pre><code>uv pip install loups\n</code></pre> <p>Or run directly without installing:</p> <pre><code>uvx loups --help\n</code></pre> <p>For isolated installation:</p> <pre><code>pipx install loups\n</code></pre> <p>This installs Loups in its own virtual environment.</p>"},{"location":"user-guide/installation/#verify-installation","title":"Verify Installation","text":"<p>After installation, verify everything is working:</p> <pre><code># Check Loups version\nloups --version\n\n# View help\nloups --help\n\n# Test with a video (if you have one)\nloups test_video.mp4\n</code></pre> <p>Installation Successful!</p> <p>If you see the help message, you're all set! </p>"},{"location":"user-guide/installation/#python-version-check","title":"Python Version Check","text":"<p>Not sure what Python version you have?</p> <pre><code># Check your Python version\npython --version\n\n# Or try python3\npython3 --version\n</code></pre>"},{"location":"user-guide/installation/#upgrading-python","title":"Upgrading Python","text":"<p>If you need to upgrade to Python 3.13+:</p>  Linux macOS Windows <pre><code># Ubuntu/Debian\nsudo apt update\nsudo apt install python3.13\n\n# Fedora\nsudo dnf install python3.13\n\n# Arch\nsudo pacman -S python\n</code></pre> <pre><code># Using Homebrew\nbrew install python@3.13\n\n# Or download from python.org\nopen https://www.python.org/downloads/\n</code></pre> <p>Download the latest Python from python.org</p> <p>Make sure to check \"Add Python to PATH\" during installation!</p>"},{"location":"user-guide/installation/#troubleshooting","title":"Troubleshooting","text":""},{"location":"user-guide/installation/#modulenotfounderror","title":"ModuleNotFoundError","text":"<p>Error: ModuleNotFoundError</p> <p>Symptom: <code>ModuleNotFoundError</code> or <code>SyntaxError</code> during installation</p> <p>Solution: You're likely using Python &lt; 3.13. Upgrade Python first.</p> <pre><code># Check version\npython --version\n\n# Use specific Python version\npython3.13 -m pip install loups\n</code></pre>"},{"location":"user-guide/installation/#first-run-is-slow","title":"First Run is Slow","text":"<p>First Execution Takes Time</p> <p>Behavior: First run takes several minutes to start</p> <p>Why: EasyOCR automatically downloads OCR models (~100MB) on first use</p> <p>Solution: This is normal! Be patient during initial setup. Subsequent runs will be much faster.</p> <p>The models are cached locally, so you only download once.</p>"},{"location":"user-guide/installation/#video-codec-issues","title":"Video Codec Issues","text":"<p>Video Won't Open</p> <p>Error: <code>cv2.error</code> or video file won't open</p> <p>Solution: Some video formats require additional codecs. Try converting to MP4 (H.264):</p> <pre><code># Using ffmpeg\nffmpeg -i input_video.mov -c:v libx264 -c:a aac output_video.mp4\n</code></pre>"},{"location":"user-guide/installation/#next-steps","title":"Next Steps","text":"<p>Now that you have Loups installed, check out:</p> <ul> <li> Quick Start Guide - Start using Loups</li> <li> CLI Reference - All command options</li> <li> Custom Templates - Create your own templates</li> </ul>"},{"location":"user-guide/installation/#dependencies","title":"Dependencies","text":"<p>Loups automatically installs these dependencies:</p> <ul> <li>easyocr - OCR text extraction</li> <li>opencv-python-headless - Video processing</li> <li>typer - CLI framework</li> <li>rich - Beautiful terminal output</li> <li>scikit-image - SSIM thumbnail matching</li> </ul> <p>No manual dependency installation needed! </p>"},{"location":"user-guide/quick-start/","title":"Quick Start","text":"<p>Get started with Loups in minutes!</p>"},{"location":"user-guide/quick-start/#5-minute-quickstart","title":"5-Minute Quickstart","text":""},{"location":"user-guide/quick-start/#basic-usage","title":"Basic Usage","text":""},{"location":"user-guide/quick-start/#lights-out-hb-games","title":"Lights Out HB Games","text":"<p>For Lights Out HB fastpitch softball games, Loups includes a bundled template:</p> <pre><code>loups game_video.mp4\n</code></pre> <p>Expected Output</p> <pre><code>Scanning video: game_video.mp4\n\n\ud83e\udd4e Scanning batters...  [Progress updates]\n\n\ud83c\udfc6 Scan complete! Found 12 batters in 5.2s\n\nYouTube Chapters:\n0:00:00 Game Start\n0:01:15 Sarah Johnson #7\n0:03:42 Emma Martinez #12\n0:05:23 Lily Garcia #9\n0:08:14 Olivia Brown #5\n...\n</code></pre>"},{"location":"user-guide/quick-start/#any-other-video","title":"Any Other Video","text":"<p>For other videos, provide your own template:</p> <pre><code>loups -t my_template.png video.mp4\n</code></pre>"},{"location":"user-guide/quick-start/#save-results-to-file","title":"Save Results to File","text":"<p>Save chapters in YouTube-ready format:</p> <pre><code>loups -o chapters.txt video.mp4\n</code></pre> <p>The <code>chapters.txt</code> file will contain:</p> <pre><code>0:00:00 Game Start\n0:01:15 Sarah Johnson #7\n0:03:42 Emma Martinez #12\n0:05:23 Lily Garcia #9\n...\n</code></pre> <p>YouTube Integration</p> <p>Copy the contents of <code>chapters.txt</code> directly into your YouTube video description!</p> <p>YouTube will automatically create clickable chapter markers.</p>"},{"location":"user-guide/quick-start/#common-examples","title":"Common Examples","text":""},{"location":"user-guide/quick-start/#process-with-custom-template","title":"Process with Custom Template","text":"<pre><code>loups -t ~/templates/scoreboard.png -o chapters.txt game.mp4\n</code></pre>"},{"location":"user-guide/quick-start/#quiet-mode-no-progress-display","title":"Quiet Mode (No Progress Display)","text":"<p>Perfect for automation and batch processing:</p> <pre><code>loups -q -o chapters.txt video.mp4\n</code></pre>"},{"location":"user-guide/quick-start/#enable-logging","title":"Enable Logging","text":"<p>Debug detection issues with logging:</p> <pre><code># Default log location (loups.log)\nloups --log video.mp4\n\n# Custom log location\nloups --log /path/to/debug.log video.mp4\n\n# Enable debug level logging\nloups --log --debug video.mp4\n</code></pre>"},{"location":"user-guide/quick-start/#extract-thumbnails","title":"Extract Thumbnails","text":""},{"location":"user-guide/quick-start/#dedicated-thumbnail-command","title":"Dedicated Thumbnail Command","text":"<pre><code># Extract thumbnail with default template\nloups video.mp4 thumbnail\n\n# Use custom thumbnail template\nloups video.mp4 thumbnail --thumbnail-template title_screen.png\n\n# Specify output location\nloups video.mp4 thumbnail --thumbnail-output ./thumb.jpg\n</code></pre>"},{"location":"user-guide/quick-start/#extract-during-chapter-scan","title":"Extract During Chapter Scan","text":"<pre><code>loups --extract-thumbnail --thumbnail-output thumb.jpg -o chapters.txt video.mp4\n</code></pre> <p>How Thumbnail Extraction Works</p> <ol> <li> Scans video frames from beginning using SSIM</li> <li> Stops at first frame exceeding similarity threshold</li> <li> Saves matched frame as JPEG</li> <li> Only scans first N seconds (default: 120s)</li> </ol>"},{"location":"user-guide/quick-start/#important-notes","title":"Important Notes","text":"<p>Option Order Matters</p> <p>Options must come BEFORE the video path:</p>  Correct Wrong <pre><code>loups -o chapters.txt -t template.png video.mp4\n</code></pre> <pre><code>loups video.mp4 -o chapters.txt -t template.png\n</code></pre> <p>Thumbnail Command Different</p> <p>The thumbnail subcommand has different syntax:</p> <pre><code>loups VIDEO thumbnail [OPTIONS]\n</code></pre> <p>The <code>VIDEO</code> comes first, then <code>thumbnail</code>, then options.</p>"},{"location":"user-guide/quick-start/#example-workflows","title":"Example Workflows","text":""},{"location":"user-guide/quick-start/#youtube-content-creation","title":"YouTube Content Creation","text":"<pre><code># Extract thumbnail\nloups game.mp4 thumbnail --thumbnail-output game_thumb.jpg\n\n# Generate chapters\nloups -o game_chapters.txt game.mp4\n\n# Upload video to YouTube\n# - Use game_thumb.jpg as custom thumbnail\n# - Paste game_chapters.txt content into description\n</code></pre>"},{"location":"user-guide/quick-start/#batch-processing-multiple-videos","title":"Batch Processing Multiple Videos","text":"<pre><code># Process all MP4 files\nfor video in *.mp4; do\n  echo \"Processing $video...\"\n  loups -q -o \"${video%.mp4}_chapters.txt\" \"$video\"\ndone\n</code></pre>"},{"location":"user-guide/quick-start/#custom-template-workflow","title":"Custom Template Workflow","text":"<pre><code># Step 1: Create template from video frame\n# (Screenshot the text overlay you want to detect)\n\n# Step 2: Test on short clip\nloups -t my_template.png --log test_clip.mp4\n\n# Step 3: Check logs to verify detection\ncat loups.log\n\n# Step 4: Process full video\nloups -t my_template.png -o chapters.txt full_video.mp4\n</code></pre>"},{"location":"user-guide/quick-start/#testing-tips","title":"Testing Tips","text":"<p>Test on Short Clips First</p> <p>Before processing long videos:</p> <ol> <li>Create a short test clip (1-2 minutes)</li> <li>Verify template detection works</li> <li>Check OCR accuracy in logs</li> <li>Then process full video</li> </ol> <pre><code># Create test clip with ffmpeg\nffmpeg -i full_video.mp4 -t 120 -c copy test_clip.mp4\n\n# Test with logging\nloups --log --debug -t template.png test_clip.mp4\n</code></pre>"},{"location":"user-guide/quick-start/#next-steps","title":"Next Steps","text":"<ul> <li> CLI Reference - All command options</li> <li> Custom Templates - Create templates for your videos</li> <li> API Reference - Use Loups programmatically</li> </ul>"},{"location":"user-guide/quick-start/#common-questions","title":"Common Questions","text":"Can I use Loups with any video? <p>Yes! As long as your video has:</p> <ul> <li>Consistent text overlays or identifying frames</li> <li>Readable text that OCR can extract</li> <li>A template image you can create</li> </ul> <p>See Custom Templates for details.</p> What video formats are supported? <p>Loups supports any format that OpenCV can read:</p> <ul> <li> MP4 (recommended)</li> <li> AVI</li> <li> MOV</li> <li> MKV</li> <li> And more</li> </ul> <p>If you encounter codec issues, convert to MP4 with H.264 encoding.</p> How accurate is the OCR? <p>Accuracy depends on:</p> <ul> <li>Video quality - Higher resolution = better OCR</li> <li>Text clarity - Clear, high-contrast text works best</li> <li>Steady frames - Motion blur reduces accuracy</li> </ul> <p>Loups uses confidence-based filtering to ensure quality results.</p> Can I process videos in batch? <p>Absolutely! Use quiet mode for scripting:</p> <pre><code>loups -q -o output.txt video.mp4\n</code></pre> <p>Check the exit code to verify success in scripts.</p>"}]}